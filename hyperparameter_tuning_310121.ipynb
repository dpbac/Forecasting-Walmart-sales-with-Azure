{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import azureml\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "import joblib\n",
    "# import json\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import BayesianParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, quniform, choice\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "\n",
    "\n",
    "# onnx\n",
    "\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "from azureml.automl.core.onnx_convert import OnnxConvertConstants\n",
    "from azureml.train.automl import constants\n",
    "import onnxruntime\n",
    "from azureml.automl.runtime.onnx_convert import OnnxInferenceHelper\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize workspace and create an Azure ML experiment\n",
    "\n",
    "To start we need to initialize our workspace and create a Azule ML experiment. It is also to remember that accessing the Azure ML workspace requires authentication with Azure.\n",
    "\n",
    "Make sure the config file is present at `.\\config.json`. This file can be downloaded from home of Azure Machine Learning Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-136695\n",
      "aml-quickstarts-136695\n",
      "southcentralus\n",
      "48a74bb7-9950-4cc1-9caa-5d50f995cc55\n"
     ]
    }
   ],
   "source": [
    "#Define the workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>hyper-lgbm-walmart-forecasting</td><td>quick-starts-ws-136695</td><td><a href=\"https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting?wsid=/subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourcegroups/aml-quickstarts-136695/workspaces/quick-starts-ws-136695\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: hyper-lgbm-walmart-forecasting,\n",
       "Workspace: quick-starts-ws-136695)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an experiment\n",
    "experiment_name = 'hyper-lgbm-walmart-forecasting'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Workspace name</th>\n",
       "      <td>quick-starts-ws-136695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azure region</th>\n",
       "      <td>southcentralus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription id</th>\n",
       "      <td>48a74bb7-9950-4cc1-9caa-5d50f995cc55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource group</th>\n",
       "      <td>aml-quickstarts-136695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>hyper-lgbm-walmart-forecasting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Workspace name                 quick-starts-ws-136695\n",
       "Azure region                           southcentralus\n",
       "Subscription id  48a74bb7-9950-4cc1-9caa-5d50f995cc55\n",
       "Resource group                 aml-quickstarts-136695\n",
       "Experiment Name        hyper-lgbm-walmart-forecasting"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data = {'Workspace name': ws.name,\n",
    "            'Azure region': ws.location,\n",
    "            'Subscription id': ws.subscription_id,\n",
    "            'Resource group': ws.resource_group,\n",
    "            'Experiment Name': experiment.name}\n",
    "\n",
    "df_data = pd.DataFrame.from_dict(data = dic_data, orient='index')\n",
    "\n",
    "df_data.rename(columns={0:''}, inplace = True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpu-cluster. Use it.\n",
      "\n",
      "Running\n",
      "{'errors': [], 'creationTime': '2021-01-31T07:49:46.271804+00:00', 'createdBy': {'userObjectId': '221cde4e-cf7d-426f-82f1-59e431567d71', 'userTenantId': '660b3398-b80e-49d2-bc5b-ac1dc93b5254', 'userName': None}, 'modifiedTime': '2021-01-31T07:52:32.270749+00:00', 'state': 'Running', 'vmSize': 'STANDARD_DS12_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Define CPU cluster name\n",
    "compute_target_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "    print(\"Found existing cpu-cluster. Use it.\")\n",
    "except ComputeTargetException:\n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_DS12_V2\",\n",
    "                                                           min_nodes=1, # when innactive\n",
    "                                                           max_nodes=4) # when busy\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    compute_target = ComputeTarget.create(ws, compute_target_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status()\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Docker environment\n",
    "\n",
    "**REVIEW AND EDIT TEXT**\n",
    "\n",
    "The remote compute will need to create a [Docker image](https://docs.docker.com/get-started/) for running the script. The Docker image is an encapsulated environment with necessary dependencies installed. In the following cell, we specify the conda packages and Python version that are needed for running the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = EnvironmentDefinition()\n",
    "# env.python.user_managed_dependencies = False\n",
    "# env.python.conda_dependencies = CondaDependencies.create(\n",
    "#     conda_packages=[\"pandas\", \"numpy\", \"scipy\", \"scikit-learn\", \"lightgbm\", \"joblib\"],\n",
    "#     python_version=\"3.6.9\",\n",
    "# )\n",
    "# env.python.conda_dependencies.add_channel(\"conda-forge\")\n",
    "# env.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The dataset used in this project is a small subset of a much bigger dataset made available at Kaggle's competition [M5 Forecasting - Accuracy Estimate the unit sales of Walmart retail goods](https://www.kaggle.com/c/m5-forecasting-accuracy/overview/description).\n",
    "\n",
    "The complete dataset covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. **The task is to forecast daily sales for the next 28 days.**\n",
    "\n",
    "In order to demonstrate the use of Azure ML in forecasting we used the available data consisting of the following files and create a reduced dataset with **10 products of the 3 Texas stores of Walmart**. \n",
    "\n",
    "* **calendar.csv** - Contains information about the dates on which the products are sold.\n",
    "* **sell_prices.csv** - Contains information about the price of the products sold per store and date.\n",
    "* **sales_train_evaluation.csv** - Includes sales [d_1 - d_1941] (labels used for the Public leaderboard)\n",
    "\n",
    "Details on how the new dataset was created can be seen in notebook [01-walmart_data_preparation](http://localhost:8888/notebooks/Capstone%20Project/notebooks/01-walmart_data_preparation.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_2_001_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_001</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_2_002_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_002</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_2_003_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_003</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_2_004_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_004</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_2_005_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_005</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_2_001_TX_1_evaluation  HOBBIES_2_001  HOBBIES_2  HOBBIES     TX_1   \n",
       "1  HOBBIES_2_002_TX_1_evaluation  HOBBIES_2_002  HOBBIES_2  HOBBIES     TX_1   \n",
       "2  HOBBIES_2_003_TX_1_evaluation  HOBBIES_2_003  HOBBIES_2  HOBBIES     TX_1   \n",
       "3  HOBBIES_2_004_TX_1_evaluation  HOBBIES_2_004  HOBBIES_2  HOBBIES     TX_1   \n",
       "4  HOBBIES_2_005_TX_1_evaluation  HOBBIES_2_005  HOBBIES_2  HOBBIES     TX_1   \n",
       "\n",
       "  state_id  demand       date  wm_yr_wk event_name_1 event_type_1  \\\n",
       "0       TX       0 2011-01-29     11101          NaN          NaN   \n",
       "1       TX       0 2011-01-29     11101          NaN          NaN   \n",
       "2       TX       0 2011-01-29     11101          NaN          NaN   \n",
       "3       TX       0 2011-01-29     11101          NaN          NaN   \n",
       "4       TX       0 2011-01-29     11101          NaN          NaN   \n",
       "\n",
       "  event_name_2 event_type_2  snap_TX  sell_price  \n",
       "0          NaN          NaN        0         NaN  \n",
       "1          NaN          NaN        0        1.97  \n",
       "2          NaN          NaN        0         NaN  \n",
       "3          NaN          NaN        0         NaN  \n",
       "4          NaN          NaN        0         NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_column_name = 'date'\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/dpbac/Forecasting-Walmart-sales-with-Azure/master/data/walmart_tx_stores_10_items.csv?token=AEBB67NDDBQFM4CVCNT5A7DACZX2A\", parse_dates=[time_column_name])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58230 entries, 0 to 58229\n",
      "Data columns (total 15 columns):\n",
      "id              58230 non-null object\n",
      "item_id         58230 non-null object\n",
      "dept_id         58230 non-null object\n",
      "cat_id          58230 non-null object\n",
      "store_id        58230 non-null object\n",
      "state_id        58230 non-null object\n",
      "demand          58230 non-null int64\n",
      "date            58230 non-null datetime64[ns]\n",
      "wm_yr_wk        58230 non-null int64\n",
      "event_name_1    4740 non-null object\n",
      "event_type_1    4740 non-null object\n",
      "event_name_2    120 non-null object\n",
      "event_type_2    120 non-null object\n",
      "snap_TX         58230 non-null int64\n",
      "sell_price      52938 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(10)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data locally\n",
    "\n",
    "# path_data = './data_walmart_tx.csv'\n",
    "# data.to_csv(path_data, index = None, header=True)\n",
    "\n",
    "# datastore_path = 'dataset/'\n",
    "\n",
    "# datastore = ws.get_default_datastore()\n",
    "# datastore.upload_files(files = ['./data_walmart_tx.csv'], \n",
    "#                        target_path = datastore_path, \n",
    "#                        overwrite = True,\n",
    "#                        show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"Datastore type: \" + datastore.datastore_type,\n",
    "#     \"Account name: \" + datastore.account_name,\n",
    "#     \"Container name: \" + datastore.container_name,\n",
    "#     sep=\"\\n\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get data reference object for the data path\n",
    "# datastore_data = ds.path(datastore_path)\n",
    "# print(datastore_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings.\n",
    "\n",
    "**REVIEW AND EDIT**\n",
    "\n",
    "Now we are ready to tune hyperparameters of the LightGBM forecast model by launching multiple runs on the cluster. In the following cell, we define the configuration of a HyperDrive job that does a parallel search of the hyperparameter space using a Bayesian sampling method. HyperDrive also supports random sampling of the parameter space.\n",
    "\n",
    "It is recommended that the maximum number of runs should be greater than or equal to 20 times the number of hyperparameters being tuned, for best results with Bayesian sampling. Specifically, it should be no less than 180 in the following case as we have 9 hyperparameters to tune. Nevertheless, we find that even with a very small amount of runs Bayesian search can achieve decent performance. Thus, the maximum number of child runs of HyperDrive `max_total_runs` is set as `20` to reduce the running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n",
      "For best results with Bayesian Sampling we recommend using a maximum number of runs greater than or equal to 20 times the number of hyperparameters being tuned. Recommendend value:140.\n"
     ]
    }
   ],
   "source": [
    "# Increase this value if you want to achieve better performance\n",
    "# max_total_runs = 20\n",
    "# script_folder = './'\n",
    "# script_params = {\"--data-folder\": datastore_data.as_mount()}\n",
    "# train_script_name = \"train_TEMP.py\" #change to train.py when everything works fine\n",
    "\n",
    "# Early Stop Policy\n",
    "# early_termination_policy = BanditPolicy(slack_factor = 0.1, # specifies the allowable slack as a ratio\n",
    "#                       evaluation_interval=2, # frequency for applying the policy\n",
    "#                       delay_evaluation=5) # delays the first policy evaluation for a specified number of intervals\n",
    "\n",
    "# Specify hyperparameter space\n",
    "param_sampling = BayesianParameterSampling(\n",
    "    {\n",
    "        \"--num-leaves\": quniform(8, 128, 1),\n",
    "        \"--min-data-in-leaf\": quniform(20, 500, 10),\n",
    "        \"--learning-rate\": choice(1e-4, 1e-3, 5e-3, 1e-2, 1.5e-2, 2e-2, 3e-2, 5e-2, 1e-1),\n",
    "        \"--feature-fraction\": uniform(0.2, 1),\n",
    "        \"--bagging-fraction\": uniform(0.1, 1),\n",
    "        \"--bagging-freq\": quniform(1, 20, 1),\n",
    "        \"--max-rounds\": quniform(50, 2000, 10),\n",
    "#         \"--max-lag\": quniform(3, 40, 1),\n",
    "#         \"--window-size\": quniform(3, 40, 1),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create an estimator for use with train.py\n",
    "\n",
    "est = Estimator(\n",
    "    source_directory = './',\n",
    "    compute_target=compute_target,\n",
    "    entry_script='train.py')\n",
    "    \n",
    "    \n",
    "# #     source_directory=script_folder,\n",
    "# #     script_params=script_params,\n",
    "#     compute_target=compute_target,\n",
    "# #     use_docker=True,\n",
    "#     entry_script=train_script_name,\n",
    "# #     environment_definition=env,\n",
    "\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    estimator=est,\n",
    "    hyperparameter_sampling=param_sampling,\n",
    "    primary_metric_name='MAE',# mean_absolute_error\n",
    "#     primary_metric_name=\"MAPE\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "    max_total_runs=20,\n",
    "    max_concurrent_runs=4,\n",
    "#     policy=early_termination_policy,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1598544893076
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# # TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
    "# early_termination_policy = <your policy here>\n",
    "\n",
    "# #TODO: Create the different params that you will be using during training\n",
    "# param_sampling = <your params here>\n",
    "\n",
    "# #TODO: Create your estimator and hyperdrive config\n",
    "# estimator = <your estimator here>\n",
    "\n",
    "# hyperdrive_run_config = <your config here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    }
   ],
   "source": [
    "# Submit hyperdrive run to the experiment \n",
    "\n",
    "hyperdrive_run = experiment.submit(config = hyperdrive_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e41ac765a846fcb49ec1d074324d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Canceled\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting/runs/HD_b4db8f59-51c2-4550-b47f-7c45b63151a9?wsid=/subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourcegroups/aml-quickstarts-136695/workspaces/quick-starts-ws-136695\", \"run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9\", \"run_properties\": {\"run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9\", \"created_utc\": \"2021-01-31T08:51:12.965096Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"MAE\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"a4af93f8-ab1c-4575-b007-717a1cd1f45f\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"20\", \"max_total_jobs\": \"20\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"--num-leaves\\\": [\\\"quniform\\\", [8, 128, 1]], \\\"--min-data-in-leaf\\\": [\\\"quniform\\\", [20, 500, 10]], \\\"--learning-rate\\\": [\\\"choice\\\", [[0.0001, 0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1]]], \\\"--feature-fraction\\\": [\\\"uniform\\\", [0.2, 1]], \\\"--bagging-fraction\\\": [\\\"uniform\\\", [0.1, 1]], \\\"--bagging-freq\\\": [\\\"quniform\\\", [1, 20, 1]], \\\"--max-rounds\\\": [\\\"quniform\\\", [50, 2000, 10]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"--num-leaves\\\": [\\\"quniform\\\", [8, 128, 1]], \\\"--min-data-in-leaf\\\": [\\\"quniform\\\", [20, 500, 10]], \\\"--learning-rate\\\": [\\\"choice\\\", [[0.0001, 0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1]]], \\\"--feature-fraction\\\": [\\\"uniform\\\", [0.2, 1]], \\\"--bagging-fraction\\\": [\\\"uniform\\\", [0.1, 1]], \\\"--bagging-freq\\\": [\\\"quniform\\\", [1, 20, 1]], \\\"--max-rounds\\\": [\\\"quniform\\\", [50, 2000, 10]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"MAE\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"MAE\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourceGroups/aml-quickstarts-136695/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-136695/experiments/hyper-lgbm-walmart-forecasting\\\", \\\"SubscriptionId\\\": \\\"48a74bb7-9950-4cc1-9caa-5d50f995cc55\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-136695\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-136695\\\", \\\"ExperimentName\\\": \\\"hyper-lgbm-walmart-forecasting\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_TEMP.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"a4af93f8-ab1c-4575-b007-717a1cd1f45f\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"6d6b1c20-be52-40e4-bd78-45093c5667b2\\\", \\\"amlClientSessionId\\\": \\\"f39c0ec4-9d1f-42b2-81d4-da34deb9e7fe\\\", \\\"subscriptionId\\\": \\\"48a74bb7-9950-4cc1-9caa-5d50f995cc55\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourceGroups/aml-quickstarts-136695/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-136695/experiments/hyper-lgbm-walmart-forecasting\\\", \\\"SubscriptionId\\\": \\\"48a74bb7-9950-4cc1-9caa-5d50f995cc55\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-136695\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-136695\\\", \\\"ExperimentName\\\": \\\"hyper-lgbm-walmart-forecasting\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_TEMP.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"a4af93f8-ab1c-4575-b007-717a1cd1f45f\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"6d6b1c20-be52-40e4-bd78-45093c5667b2\\\", \\\"amlClientSessionId\\\": \\\"f39c0ec4-9d1f-42b2-81d4-da34deb9e7fe\\\", \\\"subscriptionId\\\": \\\"48a74bb7-9950-4cc1-9caa-5d50f995cc55\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"true\", \"cancellation_requested\": \"true\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-01-31T08:51:13.622691\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-01-31T08:51:13.622691\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"38417ef1e85955a5a2852411fad499227d6b4e0b4ccb6b6186cb13c0dbf5729e\\\"\", \"progress_metadata_digest\": \"\\\"38417ef1e85955a5a2852411fad499227d6b4e0b4ccb6b6186cb13c0dbf5729e\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-01-31T08:51:13.622691\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-01-31T08:51:13.622691\\\"\", \"_aml_system_HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_0\": \"{\\\"--num-leaves\\\": 112, \\\"--min-data-in-leaf\\\": 470, \\\"--learning-rate\\\": 0.1, \\\"--feature-fraction\\\": 0.4741013337942248, \\\"--bagging-fraction\\\": 0.4666293309844428, \\\"--bagging-freq\\\": 12, \\\"--max-rounds\\\": 260}\", \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_0\": \"{\\\"--num-leaves\\\": 112, \\\"--min-data-in-leaf\\\": 470, \\\"--learning-rate\\\": 0.1, \\\"--feature-fraction\\\": 0.4741013337942248, \\\"--bagging-fraction\\\": 0.4666293309844428, \\\"--bagging-freq\\\": 12, \\\"--max-rounds\\\": 260}\", \"_aml_system_HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_1\": \"{\\\"--num-leaves\\\": 30, \\\"--min-data-in-leaf\\\": 480, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.8341322316337434, \\\"--bagging-fraction\\\": 0.36943371158678595, \\\"--bagging-freq\\\": 5, \\\"--max-rounds\\\": 950}\", \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_1\": \"{\\\"--num-leaves\\\": 30, \\\"--min-data-in-leaf\\\": 480, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.8341322316337434, \\\"--bagging-fraction\\\": 0.36943371158678595, \\\"--bagging-freq\\\": 5, \\\"--max-rounds\\\": 950}\", \"_aml_system_HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_2\": \"{\\\"--num-leaves\\\": 70, \\\"--min-data-in-leaf\\\": 500, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.20965596891403254, \\\"--bagging-fraction\\\": 0.6633483356019605, \\\"--bagging-freq\\\": 4, \\\"--max-rounds\\\": 980}\", \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_2\": \"{\\\"--num-leaves\\\": 70, \\\"--min-data-in-leaf\\\": 500, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.20965596891403254, \\\"--bagging-fraction\\\": 0.6633483356019605, \\\"--bagging-freq\\\": 4, \\\"--max-rounds\\\": 980}\", \"_aml_system_HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_3\": \"{\\\"--num-leaves\\\": 117, \\\"--min-data-in-leaf\\\": 120, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.34209452802643014, \\\"--bagging-fraction\\\": 0.19541032525032764, \\\"--bagging-freq\\\": 17, \\\"--max-rounds\\\": 110}\", \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_3\": \"{\\\"--num-leaves\\\": 117, \\\"--min-data-in-leaf\\\": 120, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.34209452802643014, \\\"--bagging-fraction\\\": 0.19541032525032764, \\\"--bagging-freq\\\": 17, \\\"--max-rounds\\\": 110}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_preparation\", \"prepare_run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_preparation\"}, \"end_time_utc\": \"2021-01-31T08:53:16.39891Z\", \"status\": \"Canceled\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg136695.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b4db8f59-51c2-4550-b47f-7c45b63151a9/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=SrYB4%2FDdPZlKTJQTB5xAH4AVSmRa7q%2F6v8Q67K7kXuU%3D&st=2021-01-31T08%3A43%3A25Z&se=2021-01-31T16%3A53%3A25Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:02:03\", \"hyper_parameters\": {\"--num-leaves\": [\"quniform\", [8, 128, 1]], \"--min-data-in-leaf\": [\"quniform\", [20, 500, 10]], \"--learning-rate\": [\"choice\", [[0.0001, 0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1]]], \"--feature-fraction\": [\"uniform\", [0.2, 1]], \"--bagging-fraction\": [\"uniform\", [0.1, 1]], \"--bagging-freq\": [\"quniform\", [1, 20, 1]], \"--max-rounds\": [\"quniform\", [50, 2000, 10]]}}, \"child_runs\": [{\"run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_3\", \"run_number\": 54, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-31T08:51:58.666671Z\", \"end_time\": \"2021-01-31T08:52:31.521948Z\", \"created_time\": \"2021-01-31T08:51:46.998534Z\", \"created_time_dt\": \"2021-01-31T08:51:46.998534Z\", \"duration\": \"0:00:44\", \"hyperdrive_id\": \"b4db8f59-51c2-4550-b47f-7c45b63151a9\", \"arguments\": null, \"param_--num-leaves\": 117, \"param_--min-data-in-leaf\": 120, \"param_--learning-rate\": 0.02, \"param_--feature-fraction\": 0.34209452802643014, \"param_--bagging-fraction\": 0.19541032525032764, \"param_--bagging-freq\": 17, \"param_--max-rounds\": 110}, {\"run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_1\", \"run_number\": 52, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-31T08:51:57.968798Z\", \"end_time\": \"2021-01-31T08:52:30.522921Z\", \"created_time\": \"2021-01-31T08:51:46.496248Z\", \"created_time_dt\": \"2021-01-31T08:51:46.496248Z\", \"duration\": \"0:00:44\", \"hyperdrive_id\": \"b4db8f59-51c2-4550-b47f-7c45b63151a9\", \"arguments\": null, \"param_--num-leaves\": 30, \"param_--min-data-in-leaf\": 480, \"param_--learning-rate\": 0.015, \"param_--feature-fraction\": 0.8341322316337434, \"param_--bagging-fraction\": 0.36943371158678595, \"param_--bagging-freq\": 5, \"param_--max-rounds\": 950}, {\"run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_0\", \"run_number\": 53, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-31T08:51:57.871902Z\", \"end_time\": \"2021-01-31T08:52:35.524762Z\", \"created_time\": \"2021-01-31T08:51:46.983729Z\", \"created_time_dt\": \"2021-01-31T08:51:46.983729Z\", \"duration\": \"0:00:48\", \"hyperdrive_id\": \"b4db8f59-51c2-4550-b47f-7c45b63151a9\", \"arguments\": null, \"param_--num-leaves\": 112, \"param_--min-data-in-leaf\": 470, \"param_--learning-rate\": 0.1, \"param_--feature-fraction\": 0.4741013337942248, \"param_--bagging-fraction\": 0.4666293309844428, \"param_--bagging-freq\": 12, \"param_--max-rounds\": 260}, {\"run_id\": \"HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_2\", \"run_number\": 55, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-31T08:51:56.763141Z\", \"end_time\": \"2021-01-31T08:52:28.394578Z\", \"created_time\": \"2021-01-31T08:51:47.232611Z\", \"created_time_dt\": \"2021-01-31T08:51:47.232611Z\", \"duration\": \"0:00:41\", \"hyperdrive_id\": \"b4db8f59-51c2-4550-b47f-7c45b63151a9\", \"arguments\": null, \"param_--num-leaves\": 70, \"param_--min-data-in-leaf\": 500, \"param_--learning-rate\": 0.02, \"param_--feature-fraction\": 0.20965596891403254, \"param_--bagging-fraction\": 0.6633483356019605, \"param_--bagging-freq\": 4, \"param_--max-rounds\": 980}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-01-31T08:51:13.696248][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-01-31T08:51:13.867346][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-01-31T08:51:13.263656][API][INFO]Experiment created\\r\\n[2021-01-31T08:51:14.9637526Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2021-01-31T08:51:45.6601329Z][SCHEDULER][INFO]Scheduling job, id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_3'\\r\\n[2021-01-31T08:51:45.7005688Z][SCHEDULER][INFO]Scheduling job, id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_2'\\r\\n[2021-01-31T08:51:45.7930821Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2021-01-31T08:51:45.7758328Z][SCHEDULER][INFO]Scheduling job, id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_0'\\r\\n[2021-01-31T08:51:45.7402406Z][SCHEDULER][INFO]Scheduling job, id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_1'\\r\\n[2021-01-31T08:51:46.6312350Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_1'\\r\\n[2021-01-31T08:51:47.2013603Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_0'\\r\\n[2021-01-31T08:51:47.4327083Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_3'\\r\\n[2021-01-31T08:51:47.3557864Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b4db8f59-51c2-4550-b47f-7c45b63151a9_2'\\r\\n[2021-01-31T08:52:45.223938][CONTROLLER][WARNING]The first 3 jobs have failed. The system is canceling the experiment. Please resolve the issues before resubmitting the experiment.\\r\\n[2021-01-31T08:52:45.223821][CONTROLLER][INFO]Experiment has been marked for cancellation.\\r\\n[2021-01-31T08:53:15.946905][CONTROLLER][WARNING]User errors were found in at least one of the child runs.\\r\\n[2021-01-31T08:53:16.892711][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.CANCELLED'.\\n\\nError occurred: User errors were found in at least one of the child runs.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_b4db8f59-51c2-4550-b47f-7c45b63151a9\n",
      "Web View: https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting/runs/HD_b4db8f59-51c2-4550-b47f-7c45b63151a9?wsid=/subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourcegroups/aml-quickstarts-136695/workspaces/quick-starts-ws-136695\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2021-01-31T08:51:13.696248][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-01-31T08:51:13.867346][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\"<START>[2021-01-31T08:51:13.263656][API][INFO]Experiment created<END>\\n\"<START>[2021-01-31T08:51:14.9637526Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: HD_b4db8f59-51c2-4550-b47f-7c45b63151a9\n",
      "Web View: https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting/runs/HD_b4db8f59-51c2-4550-b47f-7c45b63151a9?wsid=/subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourcegroups/aml-quickstarts-136695/workspaces/quick-starts-ws-136695\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show run details with the Jupyter widget\n",
    "\n",
    "RunDetails(hyperdrive_run).show()\n",
    "hyperdrive_run.wait_for_completion(show_output=True)\n",
    "hyperdrive_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Save Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your best run and save the model from that run.\n",
    "\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('NMAE:', best_run_metrics['normalized_mean_absolute_error'])\n",
    "\n",
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546650307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "parameter_values = best_run.get_details()[\"runDefinition\"][\"arguments\"]\n",
    "print(parameter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546657829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model = best_run.register_model(\n",
    "    model_name=\"hd_lgbm_walmart_forecast\", \n",
    "    model_path=\"./outputs/model.pkl\",\n",
    "    description='Best HyperDrive Walmart forecasting model'\n",
    ")\n",
    "print(\"Model successfully saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX model\n",
    "\n",
    "## Retrieve and save the best ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve and save the best model\n",
    "\n",
    "best_run, onnx_model = hyperdrive_run.get_output(return_onnx_model=True)\n",
    "onnx_model_path = \"results/best_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info < OnnxConvertConstants.OnnxIncompatiblePythonVersion:\n",
    "    python_version_compatible = True\n",
    "else:\n",
    "    python_version_compatible = False\n",
    "\n",
    "def get_onnx_res(run):\n",
    "    res_path = 'onnx_resource.json'\n",
    "    run.download_file(name=constants.MODEL_RESOURCE_PATH_ONNX, output_file_path=res_path)\n",
    "    with open(res_path) as f:\n",
    "        onnx_res = json.load(f)\n",
    "    return onnx_res\n",
    "\n",
    "if python_version_compatible:\n",
    "    test_df = test_data.to_pandas_dataframe()\n",
    "    mdl_bytes = onnx_mdl.SerializeToString()\n",
    "    onnx_res = get_onnx_res(best_run)\n",
    "\n",
    "    onnxrt_helper = OnnxInferenceHelper(mdl_bytes, onnx_res)\n",
    "    pred_onnx, pred_prob_onnx = onnxrt_helper.predict(test_df)\n",
    "\n",
    "    print(pred_onnx)\n",
    "    print(pred_prob_onnx)\n",
    "else:\n",
    "    print('Use Python version 3.6 or 3.7 to run the inference helper.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "**REVIEW AND EDIT**\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service.\n",
    "\n",
    "Now we are ready to deploy the model as a web service running in Azure Container Instance [ACI](https://azure.microsoft.com/en-us/services/container-instances/). Azure Machine Learning accomplishes this by constructing a Docker image with the scoring logic and model baked in.\n",
    "\n",
    "### Create score.py\n",
    "\n",
    "First, we will create a scoring script that will be invoked by the web service call.\n",
    "\n",
    "* Note that the scoring script must have two required functions, `init()` and `run(input_data)`.\n",
    "    - In `init()` function, you typically load the model into a global object. This function is executed only once when the Docker container is started.\n",
    "    - In `run(input_data)` function, the model is used to predict a value based on the input data. The input and output to run typically use JSON as serialization and de-serialization format but you are not limited to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def init():\n",
    "    global bst\n",
    "    model_root = os.getenv(\"AZUREML_MODEL_DIR\")\n",
    "    # The name of the folder in which to look for LightGBM model files\n",
    "    lgbm_model_folder = \"model\"\n",
    "    bst = lgb.Booster(\n",
    "        model_file=os.path.join(model_root, lgbm_model_folder, \"best-model.txt\")\n",
    "    )\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    columns = bst.feature_name()\n",
    "    data = np.array(json.loads(raw_data)[\"data\"])\n",
    "    test_df = pd.DataFrame(data=data, columns=columns)\n",
    "    # Make prediction\n",
    "    out = bst.predict(test_df)\n",
    "    return out.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create myenv.yml\n",
    "\n",
    "We also need to create an environment file so that Azure Machine Learning can install the necessary packages in the Docker image which are required by your scoring script. In this case, we need to specify packages `numpy`, `pandas`, and `lightgbm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package(\"numpy=1.16.2\")\n",
    "cd.add_conda_package(\"pandas=0.23.4\")\n",
    "cd.add_conda_package(\"lightgbm=2.3.0\")\n",
    "cd.save_to_file(base_directory=\"./\", conda_file_path=\"myenv.yml\")\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI\n",
    "\n",
    "We are almost ready to deploy. In the next cell, we first create the inference configuration and deployment configuration. Then, we deploy the model to ACI. This cell will run for several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(environment = best_run.get_environment(), \n",
    "                                   entry_script = script_file_name)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 2, \n",
    "                                               auth_enabled=True, \n",
    "                                               enable_app_insights=True,\n",
    "                                               tags = {'type': \"automl-forecasting\"},\n",
    "                                               description = \"Automl forecasting sample service\")\n",
    "\n",
    "aci_service_name = 'automl-walmart-forecast-01'\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inference_config = InferenceConfig(runtime=\"python\", \n",
    "                                   entry_script=\"score.py\", \n",
    "                                   conda_file=\"myenv.yml\")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=1,\n",
    "    memory_gb=2,\n",
    "    auth_enabled=True, \n",
    "    enable_app_insights=True,\n",
    "    tags={\"name\": \"Walmart_data\", \"framework\": \"LightGBM\"},\n",
    "    description=\"LightGBM model on Walmart dataset\",\n",
    ")\n",
    "\n",
    "aci_service_name = 'hyperdrive-walmart-forecast-01'\n",
    "print(aci_service_name)\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name=aci_service, \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
