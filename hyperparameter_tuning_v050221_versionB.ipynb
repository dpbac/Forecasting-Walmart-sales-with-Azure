{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n",
      "[GCC 7.3.0]\n",
      "Azure ML SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "### REVIEWED\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "# import shutil #\n",
    "import azureml\n",
    "import requests \n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.sampling import BayesianParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, quniform, choice\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "\n",
    "\n",
    "# onnx\n",
    "\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "from azureml.automl.core.onnx_convert import OnnxConvertConstants\n",
    "from azureml.train.automl import constants\n",
    "import onnxruntime\n",
    "from azureml.automl.runtime.onnx_convert import OnnxInferenceHelper\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from train_v050221 import *\n",
    "\n",
    "# Check system and core SDK version number\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Azure ML SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize workspace and create an Azure ML experiment\n",
    "\n",
    "To start we need to initialize our workspace and create a Azule ML experiment. It is also to remember that accessing the Azure ML workspace requires authentication with Azure.\n",
    "\n",
    "Make sure the config file is present at `.\\config.json`. This file can be downloaded from home of Azure Machine Learning Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-137315\n",
      "aml-quickstarts-137315\n",
      "southcentralus\n",
      "f9d5a085-54dc-4215-9ba6-dad5d86e60a0\n"
     ]
    }
   ],
   "source": [
    "#Define the workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>hyper-lgbm-walmart-forecasting</td><td>quick-starts-ws-137315</td><td><a href=\"https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-137315/workspaces/quick-starts-ws-137315\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: hyper-lgbm-walmart-forecasting,\n",
       "Workspace: quick-starts-ws-137315)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an experiment\n",
    "experiment_name = 'hyper-lgbm-walmart-forecasting'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Workspace name</th>\n",
       "      <td>quick-starts-ws-137315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azure region</th>\n",
       "      <td>southcentralus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription id</th>\n",
       "      <td>f9d5a085-54dc-4215-9ba6-dad5d86e60a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource group</th>\n",
       "      <td>aml-quickstarts-137315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>hyper-lgbm-walmart-forecasting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Workspace name                 quick-starts-ws-137315\n",
       "Azure region                           southcentralus\n",
       "Subscription id  f9d5a085-54dc-4215-9ba6-dad5d86e60a0\n",
       "Resource group                 aml-quickstarts-137315\n",
       "Experiment Name        hyper-lgbm-walmart-forecasting"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data = {'Workspace name': ws.name,\n",
    "            'Azure region': ws.location,\n",
    "            'Subscription id': ws.subscription_id,\n",
    "            'Resource group': ws.resource_group,\n",
    "            'Experiment Name': experiment.name}\n",
    "\n",
    "df_data = pd.DataFrame.from_dict(data = dic_data, orient='index')\n",
    "\n",
    "df_data.rename(columns={0:''}, inplace = True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpu-cluster. Use it.\n",
      "\n",
      "Running\n",
      "{'errors': [], 'creationTime': '2021-02-05T11:38:54.928783+00:00', 'createdBy': {'userObjectId': '6cef5ece-edc8-4329-a8e7-957bc3fdab99', 'userTenantId': '660b3398-b80e-49d2-bc5b-ac1dc93b5254', 'userName': None}, 'modifiedTime': '2021-02-05T11:41:26.350489+00:00', 'state': 'Running', 'vmSize': 'STANDARD_DS12_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Define CPU cluster name\n",
    "compute_target_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "    print(\"Found existing cpu-cluster. Use it.\")\n",
    "except ComputeTargetException:\n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_DS12_V2\",\n",
    "                                                           min_nodes=1, # when innactive\n",
    "                                                           max_nodes=4) # when busy\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    compute_target = ComputeTarget.create(ws, compute_target_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status()\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Docker environment\n",
    "\n",
    "The remote compute will need to create a [Docker image](https://docs.docker.com/get-started/) for running the script. The Docker image is an encapsulated environment with necessary dependencies installed. In the following cell, we specify the conda packages and Python version that are needed for running the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = EnvironmentDefinition()\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=[\"pandas\", \"numpy\", \"scipy\", \"scikit-learn\", \"lightgbm\", \"joblib\"],\n",
    "    python_version=\"3.6.2\",\n",
    ")\n",
    "env.python.conda_dependencies.add_channel(\"conda-forge\")\n",
    "env.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The dataset used in this project is a small subset of a much bigger dataset made available at Kaggle's competition [M5 Forecasting - Accuracy Estimate the unit sales of Walmart retail goods](https://www.kaggle.com/c/m5-forecasting-accuracy/overview/description).\n",
    "\n",
    "The complete dataset covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. **The task is to forecast daily sales for the next 28 days.**\n",
    "\n",
    "In order to demonstrate the use of Azure ML in forecasting we used the available data consisting of the following files and create a reduced dataset with **10 products of the 3 Texas stores of Walmart**. \n",
    "\n",
    "* **calendar.csv** - Contains information about the dates on which the products are sold.\n",
    "* **sell_prices.csv** - Contains information about the price of the products sold per store and date.\n",
    "* **sales_train_evaluation.csv** - Includes sales [d_1 - d_1941] (labels used for the Public leaderboard)\n",
    "\n",
    "Details on how the new dataset was created can be seen in notebook [01-walmart_data_preparation](http://localhost:8888/notebooks/Capstone%20Project/notebooks/01-walmart_data_preparation.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_2_001_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_001</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_2_002_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_002</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_2_003_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_003</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_2_004_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_004</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_2_005_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_005</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_2_001_TX_1_evaluation  HOBBIES_2_001  HOBBIES_2  HOBBIES     TX_1   \n",
       "1  HOBBIES_2_002_TX_1_evaluation  HOBBIES_2_002  HOBBIES_2  HOBBIES     TX_1   \n",
       "2  HOBBIES_2_003_TX_1_evaluation  HOBBIES_2_003  HOBBIES_2  HOBBIES     TX_1   \n",
       "3  HOBBIES_2_004_TX_1_evaluation  HOBBIES_2_004  HOBBIES_2  HOBBIES     TX_1   \n",
       "4  HOBBIES_2_005_TX_1_evaluation  HOBBIES_2_005  HOBBIES_2  HOBBIES     TX_1   \n",
       "\n",
       "  state_id  day  demand       date  wm_yr_wk event_name_1 event_type_1  \\\n",
       "0       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "1       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "2       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "3       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "4       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "\n",
       "  event_name_2 event_type_2  snap_TX  sell_price  \n",
       "0          NaN          NaN        0         nan  \n",
       "1          NaN          NaN        0        1.97  \n",
       "2          NaN          NaN        0         nan  \n",
       "3          NaN          NaN        0         nan  \n",
       "4          NaN          NaN        0         nan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_column_name = 'date'\n",
    "data = pd.read_csv(\"./data/walmart_tx_stores_10_items_with_day.csv\",parse_dates=[time_column_name])\n",
    "# data = pd.read_csv(\"https://raw.githubusercontent.com/dpbac/Forecasting-Walmart-sales-with-Azure/master/data/walmart_tx_stores_10_items_with_day.csv?token=AEBB67N7Y3QIIH36FY5PBEDADK6WQ\", parse_dates=[time_column_name])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58230 entries, 0 to 58229\n",
      "Data columns (total 16 columns):\n",
      "id              58230 non-null object\n",
      "item_id         58230 non-null object\n",
      "dept_id         58230 non-null object\n",
      "cat_id          58230 non-null object\n",
      "store_id        58230 non-null object\n",
      "state_id        58230 non-null object\n",
      "day             58230 non-null object\n",
      "demand          58230 non-null int64\n",
      "date            58230 non-null datetime64[ns]\n",
      "wm_yr_wk        58230 non-null int64\n",
      "event_name_1    4740 non-null object\n",
      "event_type_1    4740 non-null object\n",
      "event_name_2    120 non-null object\n",
      "event_type_2    120 non-null object\n",
      "snap_TX         58230 non-null int64\n",
      "sell_price      52938 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(11)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 28\n",
    "gap = 0\n",
    "\n",
    "data = create_features(data,forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41988 entries, 10951 to 58229\n",
      "Data columns (total 42 columns):\n",
      "id                          41988 non-null category\n",
      "item_id                     41988 non-null category\n",
      "dept_id                     41988 non-null category\n",
      "cat_id                      41988 non-null category\n",
      "store_id                    41988 non-null category\n",
      "state_id                    41988 non-null category\n",
      "day                         41988 non-null category\n",
      "demand                      41988 non-null int64\n",
      "date                        41988 non-null datetime64[ns]\n",
      "wm_yr_wk                    41988 non-null int64\n",
      "event_name_1                41988 non-null category\n",
      "event_type_1                41988 non-null category\n",
      "event_name_2                41988 non-null category\n",
      "event_type_2                41988 non-null category\n",
      "snap_TX                     41988 non-null int64\n",
      "sell_price                  41988 non-null float64\n",
      "lag_t28                     41988 non-null float64\n",
      "lag_t29                     41988 non-null float64\n",
      "lag_t30                     41988 non-null float64\n",
      "rolling_mean_t7             41988 non-null float64\n",
      "rolling_std_t7              41988 non-null float64\n",
      "rolling_mean_t30            41988 non-null float64\n",
      "rolling_std_t30             41988 non-null float64\n",
      "rolling_mean_t90            41988 non-null float64\n",
      "rolling_std_t90             41988 non-null float64\n",
      "rolling_mean_t180           41988 non-null float64\n",
      "rolling_std_t180            41988 non-null float64\n",
      "price_change_t1             41988 non-null float64\n",
      "price_change_t365           41988 non-null float64\n",
      "rolling_price_std_t7        41988 non-null float64\n",
      "rolling_price_std_t30       41988 non-null float64\n",
      "day_of_month                41988 non-null int64\n",
      "day_of_week                 41988 non-null int64\n",
      "week                        41988 non-null int64\n",
      "month                       41988 non-null int64\n",
      "year                        41988 non-null int64\n",
      "is_month_start              41988 non-null int64\n",
      "is_month_end                41988 non-null int64\n",
      "is_weekend                  41988 non-null int64\n",
      "lag_revenue_t1              41988 non-null float64\n",
      "rolling_revenue_std_t28     41988 non-null float64\n",
      "rolling_revenue_mean_t28    41988 non-null float64\n",
      "dtypes: category(11), datetime64[ns](1), float64(19), int64(11)\n",
      "memory usage: 10.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First day training dataset:2012-01-29 00:00:00\n",
      "Last day training dataset:2016-04-24 00:00:00\n",
      "First day test dataset:2016-04-25 00:00:00\n",
      "Last day test dataset:2016-05-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create a training/testing split\n",
    "\n",
    "df_train, df_test = split_train_test(data,forecast_horizon, gap)\n",
    "\n",
    "# Separate features and labels\n",
    "    \n",
    "X_train=df_train.drop(['demand'],axis=1)\n",
    "y_train=df_train['demand']\n",
    "X_test=df_test.drop(['demand'],axis=1)\n",
    "y_test=df_test['demand']\n",
    "    \n",
    "X_train.drop(columns='date',inplace=True)\n",
    "X_test.drop(columns='date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading ./test.csv\n",
      "Uploaded ./test.csv, 1 files out of an estimated total of 3\n",
      "Uploading ./data_walmart_tx.csv\n",
      "Uploaded ./data_walmart_tx.csv, 2 files out of an estimated total of 3\n",
      "Uploading ./train.csv\n",
      "Uploaded ./train.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_6769019f6b924c19957c2808b152c4b9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save data locally\n",
    "    \n",
    "path_data = './data_walmart_tx.csv'\n",
    "path_train = './train.csv'\n",
    "path_test = './test.csv'\n",
    "\n",
    "data.to_csv(path_data, index = None, header=True)\n",
    "df_train.to_csv(path_train, index = None, header=True)\n",
    "df_test.to_csv(path_test, index = None, header=True)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload_files(files = ['./data_walmart_tx.csv','./train.csv', './test.csv'], \n",
    "                       target_path = 'dataset/', \n",
    "                       overwrite = True,\n",
    "                       show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data locally\n",
    "\n",
    "# path_data = './data_walmart_tx.csv'\n",
    "# path_train = './train.csv'\n",
    "# path_test = './test.csv'\n",
    "\n",
    "# data.to_csv(path_data, index = None, header=True)\n",
    "# df_train.to_csv(path_train, index = None, header=True)\n",
    "# df_test.to_csv(path_test, index = None, header=True)\n",
    "\n",
    "# datastore = ws.get_default_datastore()\n",
    "\n",
    "# path_on_datastore = \"dataset/\"\n",
    "# datastore.upload_files(files = ['./walmart_data_tx.csv','./train.csv', './test.csv'], \n",
    "#                        target_path = 'dataset/', \n",
    "#                        overwrite = True,\n",
    "#                        show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore type: AzureBlob\n",
      "Account name: mlstrg137315\n",
      "Container name: azureml-blobstore-2a838834-d39d-4b4b-98e5-c8b54518435b\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Datastore type: \" + datastore.datastore_type,\n",
    "    \"Account name: \" + datastore.account_name,\n",
    "    \"Container name: \" + datastore.container_name,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_9757c8defdb14ec58bae10673580fcee\n"
     ]
    }
   ],
   "source": [
    "# Get data reference object for the data path\n",
    "ds_data = datastore.path('dataset/')\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.data.data_reference.DataReference"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds_data.as_mount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "df_temp = Dataset.Tabular.from_delimited_files(path=datastore.path('dataset/train.csv'))\n",
    "df_temp = df_temp.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.data.data_reference.DataReference"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datastore.path('dataset/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_revenue_t1</th>\n",
       "      <th>rolling_revenue_std_t28</th>\n",
       "      <th>rolling_revenue_mean_t28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_2_002_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_002</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_2_007_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_007</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_2_009_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_009</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.39</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_2_001_TX_2_evaluation</td>\n",
       "      <td>HOBBIES_2_001</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_2_002_TX_2_evaluation</td>\n",
       "      <td>HOBBIES_2_002</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_2_002_TX_1_evaluation  HOBBIES_2_002  HOBBIES_2  HOBBIES     TX_1   \n",
       "1  HOBBIES_2_007_TX_1_evaluation  HOBBIES_2_007  HOBBIES_2  HOBBIES     TX_1   \n",
       "2  HOBBIES_2_009_TX_1_evaluation  HOBBIES_2_009  HOBBIES_2  HOBBIES     TX_1   \n",
       "3  HOBBIES_2_001_TX_2_evaluation  HOBBIES_2_001  HOBBIES_2  HOBBIES     TX_2   \n",
       "4  HOBBIES_2_002_TX_2_evaluation  HOBBIES_2_002  HOBBIES_2  HOBBIES     TX_2   \n",
       "\n",
       "  state_id    day  demand       date  wm_yr_wk  ... day_of_week week month  \\\n",
       "0       TX  d_366       2 2012-01-29     11201  ...           6    4     1   \n",
       "1       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "2       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "3       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "4       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "\n",
       "   year  is_month_start  is_month_end  is_weekend  lag_revenue_t1  \\\n",
       "0  2012               0             0           1            0.00   \n",
       "1  2012               0             0           1            0.00   \n",
       "2  2012               0             0           1            0.00   \n",
       "3  2012               0             0           1            0.00   \n",
       "4  2012               0             0           1            0.00   \n",
       "\n",
       "   rolling_revenue_std_t28  rolling_revenue_mean_t28  \n",
       "0                     1.86                      0.63  \n",
       "1                     0.31                      0.10  \n",
       "2                     7.39                      3.39  \n",
       "3                     1.72                      0.59  \n",
       "4                     2.76                      2.04  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41148 entries, 0 to 41147\n",
      "Data columns (total 42 columns):\n",
      "id                          41148 non-null object\n",
      "item_id                     41148 non-null object\n",
      "dept_id                     41148 non-null object\n",
      "cat_id                      41148 non-null object\n",
      "store_id                    41148 non-null object\n",
      "state_id                    41148 non-null object\n",
      "day                         41148 non-null object\n",
      "demand                      41148 non-null int64\n",
      "date                        41148 non-null datetime64[ns]\n",
      "wm_yr_wk                    41148 non-null int64\n",
      "event_name_1                41148 non-null object\n",
      "event_type_1                41148 non-null object\n",
      "event_name_2                41148 non-null object\n",
      "event_type_2                41148 non-null object\n",
      "snap_TX                     41148 non-null int64\n",
      "sell_price                  41148 non-null float64\n",
      "lag_t28                     41148 non-null float64\n",
      "lag_t29                     41148 non-null float64\n",
      "lag_t30                     41148 non-null float64\n",
      "rolling_mean_t7             41148 non-null float64\n",
      "rolling_std_t7              41148 non-null float64\n",
      "rolling_mean_t30            41148 non-null float64\n",
      "rolling_std_t30             41148 non-null float64\n",
      "rolling_mean_t90            41148 non-null float64\n",
      "rolling_std_t90             41148 non-null float64\n",
      "rolling_mean_t180           41148 non-null float64\n",
      "rolling_std_t180            41148 non-null float64\n",
      "price_change_t1             41148 non-null float64\n",
      "price_change_t365           41148 non-null float64\n",
      "rolling_price_std_t7        41148 non-null float64\n",
      "rolling_price_std_t30       41148 non-null float64\n",
      "day_of_month                41148 non-null int64\n",
      "day_of_week                 41148 non-null int64\n",
      "week                        41148 non-null int64\n",
      "month                       41148 non-null int64\n",
      "year                        41148 non-null int64\n",
      "is_month_start              41148 non-null int64\n",
      "is_month_end                41148 non-null int64\n",
      "is_weekend                  41148 non-null int64\n",
      "lag_revenue_t1              41148 non-null float64\n",
      "rolling_revenue_std_t28     41148 non-null float64\n",
      "rolling_revenue_mean_t28    41148 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(19), int64(11), object(11)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperdrive Configuration\n",
    "\n",
    "Before configuring HyperDrive, we will check if the remote compute target is successfully created by submitting a job to the target. This compute target will be used by HyperDrive for hyperparameter tuning later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_9757c8defdb14ec58bae10673580fcee"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_data.as_mount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": true,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": \"2g\"\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": null,\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.20.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"pandas\",\n",
       "                \"numpy\",\n",
       "                \"scipy\",\n",
       "                \"scikit-learn\",\n",
       "                \"lightgbm\",\n",
       "                \"joblib\"\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": null\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n",
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    }
   ],
   "source": [
    "# script_params = {\"--data-folder\": ds_data.as_mount(), \"--bagging-fraction\": 0.8}\n",
    "\n",
    "# create an estimator to specify details of the job\n",
    "\n",
    "est = Estimator( \n",
    "    source_directory='./', # directory containing experiment configuration files (train.py)\n",
    "    compute_target=compute_target, # compute target where training will happen\n",
    "    entry_script='train_v050221.py',\n",
    "    use_docker=True,\n",
    "    script_params={\"--data-folder\": ds_data.as_mount(), \"--bagging-fraction\": 0.8},\n",
    "    environment_definition=env, #remove if there is an error\n",
    ")\n",
    "\n",
    "# Submit job to remote compute\n",
    "run_remote = experiment.submit(config=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script_params = {\"--bagging-fraction\": 0.8}\n",
    "# # script_params = {\"--data-folder\": ds_data.as_mount(), \"--bagging-fraction\": 0.8}\n",
    "# script_folder = './', # directory containing experiment configuration files (train.py)\n",
    "# train_script_name = 'train.py'\n",
    "\n",
    "# # create an estimator to specify details of the job\n",
    "# est = Estimator(\n",
    "#     source_directory=script_folder,\n",
    "#     script_params=script_params,\n",
    "#     compute_target=compute_target,\n",
    "#     use_docker=True,\n",
    "#     entry_script=train_script_name,\n",
    "#     environment_definition=env,\n",
    "# )\n",
    "\n",
    "# # Submit job to remote compute\n",
    "# run_remote = experiment.submit(config=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26b6eb3cacf4c47b761b2390673cf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting/runs/hyper-lgbm-walmart-forecasting_1612525704_a5906747?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-137315/workspaces/quick-starts-ws-137315\", \"run_id\": \"hyper-lgbm-walmart-forecasting_1612525704_a5906747\", \"run_properties\": {\"run_id\": \"hyper-lgbm-walmart-forecasting_1612525704_a5906747\", \"created_utc\": \"2021-02-05T11:48:29.285321Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"6a2195f9-ec3c-4777-9667-930ffb4c2a2e\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-02-05T11:56:10.024485Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=wHZPBW3mShZ9pIwU%2Bdsaw0zDbHBeJhT6%2B%2Bxx0eI%2Fit0%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/azureml-logs/55_azureml-execution-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt?sv=2019-02-02&sr=b&sig=WqqwrOMq7NM5qPkqWW8f05iQOKVlDKejGL1V50x1vRk%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/azureml-logs/65_job_prep-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt?sv=2019-02-02&sr=b&sig=KcMZfHZHCFnGHsxGDAV8jJicMEwalTXs0PGIW9UdiG4%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=QOmBEl2d8XzLKX%2BZS2ZnhdQY8RdJ%2BakK2aaHBW%2BpjQ4%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"azureml-logs/75_job_post-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/azureml-logs/75_job_post-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt?sv=2019-02-02&sr=b&sig=gppexP32XM4O2qi06iq8ng%2FscWglPq8IbFfZagzp8lA%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"azureml-logs/process_info.json\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Hy2fr7t%2Be8otvSotZD1%2BKvmgAEI7EP%2F6GEmFtrQf5ec%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"azureml-logs/process_status.json\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=BcKhMv01HJBgOKoKsJAKzy0alxofpFdB3KrJk9RkHgI%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"logs/azureml/95_azureml.log\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/logs/azureml/95_azureml.log?sv=2019-02-02&sr=b&sig=u8Sd7M7FsC19tzFTbEQKqiuXyNl%2BXtsbDy%2By1bzYU%2Fk%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=DDdzXg0Nll6abFw%2FM8pMT9BmjRpUsUPQ14f2SraolcA%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.hyper-lgbm-walmart-forecasting_1612525704_a5906747/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=4BVuQnQMi7I6cWsWNI6YmmRCucYoTRAJHJnuGsrIGMc%3D&st=2021-02-05T11%3A46%3A06Z&se=2021-02-05T19%3A56%3A06Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/20_image_build_log.txt\"], [\"azureml-logs/55_azureml-execution-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_50180f6df985e543c987a3be2428239d133c691096e8843874d13c48dea69b71_d.txt\"], [\"logs/azureml/95_azureml.log\"]], \"run_duration\": \"0:07:40\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"MAE\", \"run_id\": \"hyper-lgbm-walmart-forecasting_1612525704_a5906747\", \"categories\": [0], \"series\": [{\"data\": [26.915210841295885]}]}], \"run_logs\": \"2021-02-05 11:55:44,150|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-02-05 11:55:44,151|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-02-05 11:55:44,159|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-02-05 11:55:44,159|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-02-05 11:55:44,534|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fb21c13e950> for run source azureml.scriptrun\\n2021-02-05 11:55:44,537|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-05 11:55:44,545|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-02-05 11:55:44,545|azureml.core.authentication|DEBUG|Time to expire 1813964.45447 seconds\\n2021-02-05 11:55:44,545|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-02-05 11:55:44,546|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-02-05 11:55:44,575|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:44,576|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:44,576|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:44,576|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:44,576|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:44,577|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:44,577|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:44,615|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-02-05 11:55:44,615|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-02-05 11:55:44,681|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-02-05 11:55:44,682|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '6a2195f9-ec3c-4777-9667-930ffb4c2a2e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-02-05 11:55:44,682|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-02-05 11:55:44,682|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-02-05 11:55:44,683|azureml.WorkerPool|DEBUG|[START]\\n2021-02-05 11:55:44,683|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-02-05 11:55:44,683|azureml.RunStatusContext|DEBUG|[START]\\n2021-02-05 11:55:44,683|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-02-05 11:55:44,683|azureml.MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:44,683|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:44,683|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-02-05 11:55:44,683|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-02-05 11:55:44,684|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-137315/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747/mounts/workspaceblobstore/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747\\n2021-02-05 11:55:44,684|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-02-05 11:55:44,684|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-137315/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747/mounts/workspaceblobstore/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747\\n2021-02-05 11:55:45,458|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-02-05 11:55:45,458|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:45,459|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:45,459|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:45,459|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:45,460|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:45,460|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:45,460|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-02-05 11:55:45,491|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-02-05 11:55:45,492|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-02-05 11:55:45,545|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-02-05 11:55:45,546|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '6a2195f9-ec3c-4777-9667-930ffb4c2a2e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-02-05 11:55:45,546|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-02-05 11:55:50,446|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-05 11:55:50,447|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-05 11:55:50,459|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-05 11:55:50,717|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-02-05 11:55:50,717|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-137315/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747/mounts/workspaceblobstore/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747\\n2021-02-05 11:55:50,717|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-137315/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747/mounts/workspaceblobstore/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747 to /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-137315/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747/mounts/workspaceblobstore/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747\\n2021-02-05 11:55:50,718|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-137315/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747/mounts/workspaceblobstore/azureml/hyper-lgbm-walmart-forecasting_1612525704_a5906747\\n2021-02-05 11:55:50,718|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-02-05 11:55:50,718|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-02-05 11:55:50,718|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,718|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-05 11:55:50,718|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-05 11:55:50,719|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-05 11:55:50,719|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,719|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,719|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-02-05 11:55:50,719|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-05 11:55:50,719|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,719|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-05 11:55:50,720|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-05 11:55:50,720|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-05 11:55:50,721|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-05 11:55:50,779|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-05 11:55:50,780|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,780|azureml.MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,780|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,780|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,780|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,780|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-02-05 11:55:50,780|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-05 11:55:50,780|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-05 11:55:50,781|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-05 11:55:50,840|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-05 11:55:50,841|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-02-05 11:55:50,841|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,841|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,841|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,841|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,842|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-05 11:55:50,843|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-05 11:55:50,900|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-05 11:55:50,900|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,900|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-05 11:55:50,901|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-05 11:55:50,901|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-05 11:55:50,901|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,901|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,901|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-02-05 11:55:50,901|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-05 11:55:50,902|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:50,902|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-02-05 11:55:50,902|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-02-05 11:55:50,902|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-02-05 11:55:50,902|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-02-05 11:55:50,903|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-02-05 11:55:50,903|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-02-05 11:55:50,903|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-02-05 11:55:50,903|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-02-05 11:55:50,903|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-02-05 11:55:50,904|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-02-05 11:55:50,904|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-02-05 11:55:50,904|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-02-05 11:55:50,904|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-02-05 11:55:50,904|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-02-05 11:55:50,905|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-02-05 11:55:50,912|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-02-05 11:55:50,912|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-02-05 11:55:50,912|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-02-05 11:55:50,912|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-02-05 11:55:50,912|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-02-05 11:55:50,913|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-05 11:55:50,913|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-05 11:55:50,913|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-02-05 11:55:51,023|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-02-05 11:55:51,163|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-02-05 11:55:51,164|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-02-05 11:55:51,164|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-02-05 11:55:51,164|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.00011348724365234375 seconds.\\n\\n2021-02-05 11:55:51,164|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:51,164|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-05 11:55:51,164|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-05 11:55:51,165|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-05 11:55:51,221|azureml._SubmittedRun#hyper-lgbm-walmart-forecasting_1612525704_a5906747.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-05 11:55:56,224|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-02-05 11:55:56,282|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-02-05 11:55:56,283|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-02-05 11:55:56,283|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-02-05 11:55:56,283|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the status of the job.\n",
    "RunDetails(run_remote).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 26.915210841295885}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get validation metric value after the job finishes\n",
    "run_remote.wait_for_completion()\n",
    "run_remote.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings.\n",
    "\n",
    "**REVIEW AND EDIT**\n",
    "\n",
    "Now we are ready to tune hyperparameters of the LightGBM forecast model by launching multiple runs on the cluster. In the following cell, we define the configuration of a HyperDrive job that does a parallel search of the hyperparameter space using a Bayesian sampling method. HyperDrive also supports random sampling of the parameter space.\n",
    "\n",
    "It is recommended that the maximum number of runs should be greater than or equal to 20 times the number of hyperparameters being tuned, for best results with Bayesian sampling. Specifically, it should be no less than 180 in the following case as we have 9 hyperparameters to tune. Nevertheless, we find that even with a very small amount of runs Bayesian search can achieve decent performance. Thus, the maximum number of child runs of HyperDrive `max_total_runs` is set as `20` to reduce the running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters using HyperDrive\n",
    "\n",
    "The following code tune hyperparameters for the LightGBM forecast model.\n",
    "\n",
    "The code does a parallel search of the hyperparameter space using a `Bayesian sampling method` which does not support `termination policy`. Therefore, `policy=None`.\n",
    "\n",
    "For Bayesian Sampling we recommend using a `maximum number of runs` greater than or equal to 20 times the number of hyperparameters being tuned. The recommendend value is 140. We set the maximum number of child runs of HyperDrive `max_total_runs` to `20` to reduce the running time. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**If I have the time:**\n",
    "Therefore, we set the maximum number of child runs of HyperDrive `max_total_runs` to `140`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.train.estimator._estimator:'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
     ]
    }
   ],
   "source": [
    "# Increase this value if you want to achieve better performance\n",
    "max_total_runs = 20\n",
    "\n",
    "\n",
    "# script_folder = './', # directory containing experiment configuration files (train.py)\n",
    "# # script_params = {\"--data-folder\": './'}\n",
    "# train_script_name = 'train.py'\n",
    "\n",
    "# # Create an estimator for use with train.py\n",
    "# est = Estimator(\n",
    "#     source_directory=script_folder,\n",
    "# #     script_params=script_params,\n",
    "#     compute_target=compute_target,\n",
    "#     use_docker=True,\n",
    "#     entry_script=train_script_name,\n",
    "#     environment_definition=env,\n",
    "# )\n",
    "\n",
    "est = Estimator( \n",
    "    source_directory='./', # directory containing experiment configuration files (train.py)\n",
    "    compute_target=compute_target, # compute target where training will happen\n",
    "    entry_script='train_v050221.py',\n",
    "    use_docker=True,\n",
    "    script_params={\"--data-folder\": ds_data.as_mount()},\n",
    "    environment_definition=env, #remove if there is an error\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Specify hyperparameter space\n",
    "param_sampling = BayesianParameterSampling(\n",
    "    {\n",
    "        \"--num-leaves\": quniform(8, 128, 1),\n",
    "        \"--min-data-in-leaf\": quniform(20, 500, 10),\n",
    "        \"--learning-rate\": choice(\n",
    "            1e-4, 1e-3, 5e-3, 1e-2, 1.5e-2, 2e-2, 3e-2, 5e-2, 1e-1\n",
    "        ),\n",
    "        \"--feature-fraction\": uniform(0.2, 1),\n",
    "        \"--bagging-fraction\": uniform(0.1, 1),\n",
    "        \"--bagging-freq\": quniform(1, 20, 1),\n",
    "        \"--max-rounds\": quniform(50, 2000, 10),\n",
    "#         \"--max-lag\": quniform(3, 40, 1),\n",
    "#         \"--window-size\": quniform(3, 40, 1),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    estimator=est,\n",
    "    hyperparameter_sampling=param_sampling,\n",
    "    primary_metric_name='MAE',# mean_absolute_error\n",
    "    primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "    max_total_runs=max_total_runs, \n",
    "    max_concurrent_runs=4,\n",
    "    policy=None, #Bayesian sampling does not support early termination policies.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    }
   ],
   "source": [
    "# Submit hyperdrive run to the experiment \n",
    "\n",
    "hyperdrive_run = experiment.submit(config = hyperdrive_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8117786d6034e0083c316fc1dbe5dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting/runs/HD_45883ed0-be2a-44c6-823d-a646b28c2f1a?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-137315/workspaces/quick-starts-ws-137315\", \"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"run_properties\": {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"created_utc\": \"2021-02-05T11:56:45.828849Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"MAE\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"a9f40ad3-ce7a-4990-aeeb-7e2f1e600870\", \"score\": \"26.820741669022762\", \"best_child_run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"20\", \"max_total_jobs\": \"20\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"--num-leaves\\\": [\\\"quniform\\\", [8, 128, 1]], \\\"--min-data-in-leaf\\\": [\\\"quniform\\\", [20, 500, 10]], \\\"--learning-rate\\\": [\\\"choice\\\", [[0.0001, 0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1]]], \\\"--feature-fraction\\\": [\\\"uniform\\\", [0.2, 1]], \\\"--bagging-fraction\\\": [\\\"uniform\\\", [0.1, 1]], \\\"--bagging-freq\\\": [\\\"quniform\\\", [1, 20, 1]], \\\"--max-rounds\\\": [\\\"quniform\\\", [50, 2000, 10]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"--num-leaves\\\": [\\\"quniform\\\", [8, 128, 1]], \\\"--min-data-in-leaf\\\": [\\\"quniform\\\", [20, 500, 10]], \\\"--learning-rate\\\": [\\\"choice\\\", [[0.0001, 0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1]]], \\\"--feature-fraction\\\": [\\\"uniform\\\", [0.2, 1]], \\\"--bagging-fraction\\\": [\\\"uniform\\\", [0.1, 1]], \\\"--bagging-freq\\\": [\\\"quniform\\\", [1, 20, 1]], \\\"--max-rounds\\\": [\\\"quniform\\\", [50, 2000, 10]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"MAE\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"MAE\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.api.azureml.ms\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourceGroups/aml-quickstarts-137315/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-137315/experiments/hyper-lgbm-walmart-forecasting\\\", \\\"SubscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-137315\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-137315\\\", \\\"ExperimentName\\\": \\\"hyper-lgbm-walmart-forecasting\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_v050221.py\\\", \\\"arguments\\\": [\\\"--data-folder\\\", \\\"$AZUREML_DATAREFERENCE_9757c8defdb14ec58bae10673580fcee\\\"], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults~=1.20.0\\\"]}, \\\"pandas\\\", \\\"numpy\\\", \\\"scipy\\\", \\\"scikit-learn\\\", \\\"lightgbm\\\", \\\"joblib\\\"], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"9757c8defdb14ec58bae10673580fcee\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": \\\"dataset/\\\", \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"a9f40ad3-ce7a-4990-aeeb-7e2f1e600870\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"0aae2b62-00df-494d-94d7-580bf5b5e225\\\", \\\"amlClientSessionId\\\": \\\"ee014fd3-880c-4784-b6fd-7c041e642763\\\", \\\"subscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.api.azureml.ms\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourceGroups/aml-quickstarts-137315/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-137315/experiments/hyper-lgbm-walmart-forecasting\\\", \\\"SubscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-137315\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-137315\\\", \\\"ExperimentName\\\": \\\"hyper-lgbm-walmart-forecasting\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_v050221.py\\\", \\\"arguments\\\": [\\\"--data-folder\\\", \\\"$AZUREML_DATAREFERENCE_9757c8defdb14ec58bae10673580fcee\\\"], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults~=1.20.0\\\"]}, \\\"pandas\\\", \\\"numpy\\\", \\\"scipy\\\", \\\"scikit-learn\\\", \\\"lightgbm\\\", \\\"joblib\\\"], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"9757c8defdb14ec58bae10673580fcee\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": \\\"dataset/\\\", \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"a9f40ad3-ce7a-4990-aeeb-7e2f1e600870\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"0aae2b62-00df-494d-94d7-580bf5b5e225\\\", \\\"amlClientSessionId\\\": \\\"ee014fd3-880c-4784-b6fd-7c041e642763\\\", \\\"subscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-02-05T11:56:46.450528\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-02-05T11:56:46.450528\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"e4c7de88e957c79a1087fb87dbb9ac5a21bd8fa753a5156153b416767d7fc4e4\\\"\", \"progress_metadata_digest\": \"\\\"e4c7de88e957c79a1087fb87dbb9ac5a21bd8fa753a5156153b416767d7fc4e4\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-02-05T11:56:46.450528\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-02-05T11:56:46.450528\\\"\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_0\": \"{\\\"--num-leaves\\\": 58, \\\"--min-data-in-leaf\\\": 370, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.2817556001099439, \\\"--bagging-fraction\\\": 0.9360968691055104, \\\"--bagging-freq\\\": 19, \\\"--max-rounds\\\": 1810}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_0\": \"{\\\"--num-leaves\\\": 58, \\\"--min-data-in-leaf\\\": 370, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.2817556001099439, \\\"--bagging-fraction\\\": 0.9360968691055104, \\\"--bagging-freq\\\": 19, \\\"--max-rounds\\\": 1810}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_1\": \"{\\\"--num-leaves\\\": 116, \\\"--min-data-in-leaf\\\": 380, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.6572691134767058, \\\"--bagging-fraction\\\": 0.5450046456492748, \\\"--bagging-freq\\\": 5, \\\"--max-rounds\\\": 300}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_1\": \"{\\\"--num-leaves\\\": 116, \\\"--min-data-in-leaf\\\": 380, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.6572691134767058, \\\"--bagging-fraction\\\": 0.5450046456492748, \\\"--bagging-freq\\\": 5, \\\"--max-rounds\\\": 300}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_2\": \"{\\\"--num-leaves\\\": 94, \\\"--min-data-in-leaf\\\": 200, \\\"--learning-rate\\\": 0.001, \\\"--feature-fraction\\\": 0.49504210855800096, \\\"--bagging-fraction\\\": 0.8000959006592159, \\\"--bagging-freq\\\": 19, \\\"--max-rounds\\\": 1900}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_2\": \"{\\\"--num-leaves\\\": 94, \\\"--min-data-in-leaf\\\": 200, \\\"--learning-rate\\\": 0.001, \\\"--feature-fraction\\\": 0.49504210855800096, \\\"--bagging-fraction\\\": 0.8000959006592159, \\\"--bagging-freq\\\": 19, \\\"--max-rounds\\\": 1900}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_3\": \"{\\\"--num-leaves\\\": 51, \\\"--min-data-in-leaf\\\": 110, \\\"--learning-rate\\\": 0.001, \\\"--feature-fraction\\\": 0.6378415283647676, \\\"--bagging-fraction\\\": 0.8270430331110409, \\\"--bagging-freq\\\": 10, \\\"--max-rounds\\\": 510}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_3\": \"{\\\"--num-leaves\\\": 51, \\\"--min-data-in-leaf\\\": 110, \\\"--learning-rate\\\": 0.001, \\\"--feature-fraction\\\": 0.6378415283647676, \\\"--bagging-fraction\\\": 0.8270430331110409, \\\"--bagging-freq\\\": 10, \\\"--max-rounds\\\": 510}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_preparation\", \"prepare_run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_preparation\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_4\": \"{\\\"--num-leaves\\\": 116, \\\"--min-data-in-leaf\\\": 230, \\\"--learning-rate\\\": 0.03, \\\"--feature-fraction\\\": 0.5821509403811961, \\\"--bagging-fraction\\\": 0.6164466187591149, \\\"--bagging-freq\\\": 15, \\\"--max-rounds\\\": 280}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_4\": \"{\\\"--num-leaves\\\": 116, \\\"--min-data-in-leaf\\\": 230, \\\"--learning-rate\\\": 0.03, \\\"--feature-fraction\\\": 0.5821509403811961, \\\"--bagging-fraction\\\": 0.6164466187591149, \\\"--bagging-freq\\\": 15, \\\"--max-rounds\\\": 280}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_5\": \"{\\\"--num-leaves\\\": 65, \\\"--min-data-in-leaf\\\": 70, \\\"--learning-rate\\\": 0.0001, \\\"--feature-fraction\\\": 0.9537977312780335, \\\"--bagging-fraction\\\": 0.9958570390435869, \\\"--bagging-freq\\\": 3, \\\"--max-rounds\\\": 720}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_5\": \"{\\\"--num-leaves\\\": 65, \\\"--min-data-in-leaf\\\": 70, \\\"--learning-rate\\\": 0.0001, \\\"--feature-fraction\\\": 0.9537977312780335, \\\"--bagging-fraction\\\": 0.9958570390435869, \\\"--bagging-freq\\\": 3, \\\"--max-rounds\\\": 720}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_6\": \"{\\\"--num-leaves\\\": 105, \\\"--min-data-in-leaf\\\": 60, \\\"--learning-rate\\\": 0.01, \\\"--feature-fraction\\\": 0.34136885096900693, \\\"--bagging-fraction\\\": 0.1099158238287874, \\\"--bagging-freq\\\": 7, \\\"--max-rounds\\\": 700}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_6\": \"{\\\"--num-leaves\\\": 105, \\\"--min-data-in-leaf\\\": 60, \\\"--learning-rate\\\": 0.01, \\\"--feature-fraction\\\": 0.34136885096900693, \\\"--bagging-fraction\\\": 0.1099158238287874, \\\"--bagging-freq\\\": 7, \\\"--max-rounds\\\": 700}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_7\": \"{\\\"--num-leaves\\\": 38, \\\"--min-data-in-leaf\\\": 370, \\\"--learning-rate\\\": 0.005, \\\"--feature-fraction\\\": 0.7766567752612952, \\\"--bagging-fraction\\\": 0.9386704293568632, \\\"--bagging-freq\\\": 12, \\\"--max-rounds\\\": 220}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_7\": \"{\\\"--num-leaves\\\": 38, \\\"--min-data-in-leaf\\\": 370, \\\"--learning-rate\\\": 0.005, \\\"--feature-fraction\\\": 0.7766567752612952, \\\"--bagging-fraction\\\": 0.9386704293568632, \\\"--bagging-freq\\\": 12, \\\"--max-rounds\\\": 220}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_8\": \"{\\\"--num-leaves\\\": 34, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.3352773138185662, \\\"--bagging-fraction\\\": 0.656509407589545, \\\"--bagging-freq\\\": 12, \\\"--max-rounds\\\": 1850}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_8\": \"{\\\"--num-leaves\\\": 34, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.3352773138185662, \\\"--bagging-fraction\\\": 0.656509407589545, \\\"--bagging-freq\\\": 12, \\\"--max-rounds\\\": 1850}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_9\": \"{\\\"--num-leaves\\\": 125, \\\"--min-data-in-leaf\\\": 480, \\\"--learning-rate\\\": 0.005, \\\"--feature-fraction\\\": 0.22273655298388795, \\\"--bagging-fraction\\\": 0.3129793203368333, \\\"--bagging-freq\\\": 20, \\\"--max-rounds\\\": 1420}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_9\": \"{\\\"--num-leaves\\\": 125, \\\"--min-data-in-leaf\\\": 480, \\\"--learning-rate\\\": 0.005, \\\"--feature-fraction\\\": 0.22273655298388795, \\\"--bagging-fraction\\\": 0.3129793203368333, \\\"--bagging-freq\\\": 20, \\\"--max-rounds\\\": 1420}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_10\": \"{\\\"--num-leaves\\\": 99, \\\"--min-data-in-leaf\\\": 210, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.5582677365360134, \\\"--bagging-fraction\\\": 0.2654009957849284, \\\"--bagging-freq\\\": 17, \\\"--max-rounds\\\": 1910}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_10\": \"{\\\"--num-leaves\\\": 99, \\\"--min-data-in-leaf\\\": 210, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.5582677365360134, \\\"--bagging-fraction\\\": 0.2654009957849284, \\\"--bagging-freq\\\": 17, \\\"--max-rounds\\\": 1910}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_11\": \"{\\\"--num-leaves\\\": 68, \\\"--min-data-in-leaf\\\": 60, \\\"--learning-rate\\\": 0.03, \\\"--feature-fraction\\\": 0.25342705492696765, \\\"--bagging-fraction\\\": 0.9892651286605469, \\\"--bagging-freq\\\": 13, \\\"--max-rounds\\\": 710}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_11\": \"{\\\"--num-leaves\\\": 68, \\\"--min-data-in-leaf\\\": 60, \\\"--learning-rate\\\": 0.03, \\\"--feature-fraction\\\": 0.25342705492696765, \\\"--bagging-fraction\\\": 0.9892651286605469, \\\"--bagging-freq\\\": 13, \\\"--max-rounds\\\": 710}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_12\": \"{\\\"--num-leaves\\\": 94, \\\"--min-data-in-leaf\\\": 140, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.8944536183795284, \\\"--bagging-fraction\\\": 0.6430789965644929, \\\"--bagging-freq\\\": 2, \\\"--max-rounds\\\": 450}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_12\": \"{\\\"--num-leaves\\\": 94, \\\"--min-data-in-leaf\\\": 140, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.8944536183795284, \\\"--bagging-fraction\\\": 0.6430789965644929, \\\"--bagging-freq\\\": 2, \\\"--max-rounds\\\": 450}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_13\": \"{\\\"--num-leaves\\\": 126, \\\"--min-data-in-leaf\\\": 480, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.47398794584358245, \\\"--bagging-fraction\\\": 0.44560011279614137, \\\"--bagging-freq\\\": 19, \\\"--max-rounds\\\": 1420}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_13\": \"{\\\"--num-leaves\\\": 126, \\\"--min-data-in-leaf\\\": 480, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.47398794584358245, \\\"--bagging-fraction\\\": 0.44560011279614137, \\\"--bagging-freq\\\": 19, \\\"--max-rounds\\\": 1420}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_14\": \"{\\\"--num-leaves\\\": 75, \\\"--min-data-in-leaf\\\": 360, \\\"--learning-rate\\\": 0.005, \\\"--feature-fraction\\\": 0.6290722554806686, \\\"--bagging-fraction\\\": 0.4335119812936685, \\\"--bagging-freq\\\": 6, \\\"--max-rounds\\\": 530}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_14\": \"{\\\"--num-leaves\\\": 75, \\\"--min-data-in-leaf\\\": 360, \\\"--learning-rate\\\": 0.005, \\\"--feature-fraction\\\": 0.6290722554806686, \\\"--bagging-fraction\\\": 0.4335119812936685, \\\"--bagging-freq\\\": 6, \\\"--max-rounds\\\": 530}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_15\": \"{\\\"--num-leaves\\\": 96, \\\"--min-data-in-leaf\\\": 450, \\\"--learning-rate\\\": 0.1, \\\"--feature-fraction\\\": 0.7004735549105927, \\\"--bagging-fraction\\\": 0.4087671886336549, \\\"--bagging-freq\\\": 15, \\\"--max-rounds\\\": 1790}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_15\": \"{\\\"--num-leaves\\\": 96, \\\"--min-data-in-leaf\\\": 450, \\\"--learning-rate\\\": 0.1, \\\"--feature-fraction\\\": 0.7004735549105927, \\\"--bagging-fraction\\\": 0.4087671886336549, \\\"--bagging-freq\\\": 15, \\\"--max-rounds\\\": 1790}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_16\": \"{\\\"--num-leaves\\\": 26, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.2, \\\"--bagging-fraction\\\": 1.0, \\\"--bagging-freq\\\": 9, \\\"--max-rounds\\\": 1850}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_16\": \"{\\\"--num-leaves\\\": 26, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.02, \\\"--feature-fraction\\\": 0.2, \\\"--bagging-fraction\\\": 1.0, \\\"--bagging-freq\\\": 9, \\\"--max-rounds\\\": 1850}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_17\": \"{\\\"--num-leaves\\\": 39, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.1, \\\"--feature-fraction\\\": 1.0, \\\"--bagging-fraction\\\": 1.0, \\\"--bagging-freq\\\": 18, \\\"--max-rounds\\\": 1860}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_17\": \"{\\\"--num-leaves\\\": 39, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.1, \\\"--feature-fraction\\\": 1.0, \\\"--bagging-fraction\\\": 1.0, \\\"--bagging-freq\\\": 18, \\\"--max-rounds\\\": 1860}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18\": \"{\\\"--num-leaves\\\": 88, \\\"--min-data-in-leaf\\\": 140, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.8560920060533119, \\\"--bagging-fraction\\\": 0.6640337972592919, \\\"--bagging-freq\\\": 3, \\\"--max-rounds\\\": 460}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18\": \"{\\\"--num-leaves\\\": 88, \\\"--min-data-in-leaf\\\": 140, \\\"--learning-rate\\\": 0.015, \\\"--feature-fraction\\\": 0.8560920060533119, \\\"--bagging-fraction\\\": 0.6640337972592919, \\\"--bagging-freq\\\": 3, \\\"--max-rounds\\\": 460}\", \"_aml_system_HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_19\": \"{\\\"--num-leaves\\\": 37, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.03, \\\"--feature-fraction\\\": 0.35117752823712367, \\\"--bagging-fraction\\\": 0.41601463279675777, \\\"--bagging-freq\\\": 5, \\\"--max-rounds\\\": 1850}\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_19\": \"{\\\"--num-leaves\\\": 37, \\\"--min-data-in-leaf\\\": 150, \\\"--learning-rate\\\": 0.03, \\\"--feature-fraction\\\": 0.35117752823712367, \\\"--bagging-fraction\\\": 0.41601463279675777, \\\"--bagging-freq\\\": 5, \\\"--max-rounds\\\": 1850}\"}, \"end_time_utc\": \"2021-02-05T12:09:51.972233Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg137315.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_45883ed0-be2a-44c6-823d-a646b28c2f1a/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=CpBrQ4mU82enk3DgK5s18HSCoPxzi1rx309y1bdAPYA%3D&st=2021-02-05T11%3A59%3A58Z&se=2021-02-05T20%3A09%3A58Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:13:06\", \"hyper_parameters\": {\"--num-leaves\": [\"quniform\", [8, 128, 1]], \"--min-data-in-leaf\": [\"quniform\", [20, 500, 10]], \"--learning-rate\": [\"choice\", [[0.0001, 0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1]]], \"--feature-fraction\": [\"uniform\", [0.2, 1]], \"--bagging-fraction\": [\"uniform\", [0.1, 1]], \"--bagging-freq\": [\"quniform\", [1, 20, 1]], \"--max-rounds\": [\"quniform\", [50, 2000, 10]]}}, \"child_runs\": [{\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_2\", \"run_number\": 4, \"metric\": 26.90407661, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:57:28.048455Z\", \"end_time\": \"2021-02-05T11:58:30.084133Z\", \"created_time\": \"2021-02-05T11:57:17.941584Z\", \"created_time_dt\": \"2021-02-05T11:57:17.941584Z\", \"duration\": \"0:01:12\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 94, \"param_--min-data-in-leaf\": 200, \"param_--learning-rate\": 0.001, \"param_--feature-fraction\": 0.49504210855800096, \"param_--bagging-fraction\": 0.8000959006592159, \"param_--bagging-freq\": 19, \"param_--max-rounds\": 1900, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_0\", \"run_number\": 5, \"metric\": 26.91962524, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:57:28.005059Z\", \"end_time\": \"2021-02-05T11:58:35.975452Z\", \"created_time\": \"2021-02-05T11:57:17.942151Z\", \"created_time_dt\": \"2021-02-05T11:57:17.942151Z\", \"duration\": \"0:01:18\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 58, \"param_--min-data-in-leaf\": 370, \"param_--learning-rate\": 0.02, \"param_--feature-fraction\": 0.2817556001099439, \"param_--bagging-fraction\": 0.9360968691055104, \"param_--bagging-freq\": 19, \"param_--max-rounds\": 1810, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_3\", \"run_number\": 6, \"metric\": 26.90785245, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:57:30.513166Z\", \"end_time\": \"2021-02-05T11:58:26.510574Z\", \"created_time\": \"2021-02-05T11:57:18.41433Z\", \"created_time_dt\": \"2021-02-05T11:57:18.41433Z\", \"duration\": \"0:01:08\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 51, \"param_--min-data-in-leaf\": 110, \"param_--learning-rate\": 0.001, \"param_--feature-fraction\": 0.6378415283647676, \"param_--bagging-fraction\": 0.8270430331110409, \"param_--bagging-freq\": 10, \"param_--max-rounds\": 510, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_1\", \"run_number\": 7, \"metric\": 26.91011905, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:57:29.653631Z\", \"end_time\": \"2021-02-05T11:58:25.550258Z\", \"created_time\": \"2021-02-05T11:57:18.802026Z\", \"created_time_dt\": \"2021-02-05T11:57:18.802026Z\", \"duration\": \"0:01:06\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 116, \"param_--min-data-in-leaf\": 380, \"param_--learning-rate\": 0.015, \"param_--feature-fraction\": 0.6572691134767058, \"param_--bagging-fraction\": 0.5450046456492748, \"param_--bagging-freq\": 5, \"param_--max-rounds\": 300, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_7\", \"run_number\": 8, \"metric\": 26.90476207, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:59:33.152803Z\", \"end_time\": \"2021-02-05T12:00:27.280775Z\", \"created_time\": \"2021-02-05T11:59:22.206179Z\", \"created_time_dt\": \"2021-02-05T11:59:22.206179Z\", \"duration\": \"0:01:05\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 38, \"param_--min-data-in-leaf\": 370, \"param_--learning-rate\": 0.005, \"param_--feature-fraction\": 0.7766567752612952, \"param_--bagging-fraction\": 0.9386704293568632, \"param_--bagging-freq\": 12, \"param_--max-rounds\": 220, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_6\", \"run_number\": 9, \"metric\": 26.94030775, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:59:33.736444Z\", \"end_time\": \"2021-02-05T12:00:23.624969Z\", \"created_time\": \"2021-02-05T11:59:22.713285Z\", \"created_time_dt\": \"2021-02-05T11:59:22.713285Z\", \"duration\": \"0:01:00\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 105, \"param_--min-data-in-leaf\": 60, \"param_--learning-rate\": 0.01, \"param_--feature-fraction\": 0.34136885096900693, \"param_--bagging-fraction\": 0.1099158238287874, \"param_--bagging-freq\": 7, \"param_--max-rounds\": 700, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_5\", \"run_number\": 10, \"metric\": 26.90488175, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:59:34.146005Z\", \"end_time\": \"2021-02-05T12:01:30.216986Z\", \"created_time\": \"2021-02-05T11:59:22.736872Z\", \"created_time_dt\": \"2021-02-05T11:59:22.736872Z\", \"duration\": \"0:02:07\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 65, \"param_--min-data-in-leaf\": 70, \"param_--learning-rate\": 0.0001, \"param_--feature-fraction\": 0.9537977312780335, \"param_--bagging-fraction\": 0.9958570390435869, \"param_--bagging-freq\": 3, \"param_--max-rounds\": 720, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_4\", \"run_number\": 11, \"metric\": 26.96636323, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T11:59:32.80682Z\", \"end_time\": \"2021-02-05T12:00:36.252994Z\", \"created_time\": \"2021-02-05T11:59:23.41994Z\", \"created_time_dt\": \"2021-02-05T11:59:23.41994Z\", \"duration\": \"0:01:12\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 116, \"param_--min-data-in-leaf\": 230, \"param_--learning-rate\": 0.03, \"param_--feature-fraction\": 0.5821509403811961, \"param_--bagging-fraction\": 0.6164466187591149, \"param_--bagging-freq\": 15, \"param_--max-rounds\": 280, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_9\", \"run_number\": 12, \"metric\": 26.9047619, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:01:10.123399Z\", \"end_time\": \"2021-02-05T12:01:54.454849Z\", \"created_time\": \"2021-02-05T12:00:55.756409Z\", \"created_time_dt\": \"2021-02-05T12:00:55.756409Z\", \"duration\": \"0:00:58\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 125, \"param_--min-data-in-leaf\": 480, \"param_--learning-rate\": 0.005, \"param_--feature-fraction\": 0.22273655298388795, \"param_--bagging-fraction\": 0.3129793203368333, \"param_--bagging-freq\": 20, \"param_--max-rounds\": 1420, \"best_metric\": 26.90407661}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_8\", \"run_number\": 13, \"metric\": 26.87029937, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:01:10.19248Z\", \"end_time\": \"2021-02-05T12:02:00.546953Z\", \"created_time\": \"2021-02-05T12:00:56.280448Z\", \"created_time_dt\": \"2021-02-05T12:00:56.280448Z\", \"duration\": \"0:01:04\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 34, \"param_--min-data-in-leaf\": 150, \"param_--learning-rate\": 0.02, \"param_--feature-fraction\": 0.3352773138185662, \"param_--bagging-fraction\": 0.656509407589545, \"param_--bagging-freq\": 12, \"param_--max-rounds\": 1850, \"best_metric\": 26.87029937}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_10\", \"run_number\": 14, \"metric\": 26.93077928, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:01:41.755829Z\", \"end_time\": \"2021-02-05T12:02:39.577985Z\", \"created_time\": \"2021-02-05T12:01:28.651575Z\", \"created_time_dt\": \"2021-02-05T12:01:28.651575Z\", \"duration\": \"0:01:10\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 99, \"param_--min-data-in-leaf\": 210, \"param_--learning-rate\": 0.015, \"param_--feature-fraction\": 0.5582677365360134, \"param_--bagging-fraction\": 0.2654009957849284, \"param_--bagging-freq\": 17, \"param_--max-rounds\": 1910, \"best_metric\": 26.87029937}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_11\", \"run_number\": 15, \"metric\": 26.94512112, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:02:11.951035Z\", \"end_time\": \"2021-02-05T12:03:10.910569Z\", \"created_time\": \"2021-02-05T12:02:00.16878Z\", \"created_time_dt\": \"2021-02-05T12:02:00.16878Z\", \"duration\": \"0:01:10\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 68, \"param_--min-data-in-leaf\": 60, \"param_--learning-rate\": 0.03, \"param_--feature-fraction\": 0.25342705492696765, \"param_--bagging-fraction\": 0.9892651286605469, \"param_--bagging-freq\": 13, \"param_--max-rounds\": 710, \"best_metric\": 26.87029937}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_12\", \"run_number\": 16, \"metric\": 26.87452421, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:02:40.878726Z\", \"end_time\": \"2021-02-05T12:04:19.392291Z\", \"created_time\": \"2021-02-05T12:02:31.981739Z\", \"created_time_dt\": \"2021-02-05T12:02:31.981739Z\", \"duration\": \"0:01:47\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 94, \"param_--min-data-in-leaf\": 140, \"param_--learning-rate\": 0.015, \"param_--feature-fraction\": 0.8944536183795284, \"param_--bagging-fraction\": 0.6430789965644929, \"param_--bagging-freq\": 2, \"param_--max-rounds\": 450, \"best_metric\": 26.87029937}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_13\", \"run_number\": 17, \"metric\": 26.9047619, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:02:43.69549Z\", \"end_time\": \"2021-02-05T12:04:12.243023Z\", \"created_time\": \"2021-02-05T12:02:32.323595Z\", \"created_time_dt\": \"2021-02-05T12:02:32.323595Z\", \"duration\": \"0:01:39\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 126, \"param_--min-data-in-leaf\": 480, \"param_--learning-rate\": 0.015, \"param_--feature-fraction\": 0.47398794584358245, \"param_--bagging-fraction\": 0.44560011279614137, \"param_--bagging-freq\": 19, \"param_--max-rounds\": 1420, \"best_metric\": 26.87029937}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_14\", \"run_number\": 18, \"metric\": 26.9047619, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:03:48.999908Z\", \"end_time\": \"2021-02-05T12:04:30.253975Z\", \"created_time\": \"2021-02-05T12:03:36.787107Z\", \"created_time_dt\": \"2021-02-05T12:03:36.787107Z\", \"duration\": \"0:00:53\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 75, \"param_--min-data-in-leaf\": 360, \"param_--learning-rate\": 0.005, \"param_--feature-fraction\": 0.6290722554806686, \"param_--bagging-fraction\": 0.4335119812936685, \"param_--bagging-freq\": 6, \"param_--max-rounds\": 530, \"best_metric\": 26.87029937}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_15\", \"run_number\": 19, \"metric\": 26.9047619, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:04:20.28649Z\", \"end_time\": \"2021-02-05T12:05:49.372567Z\", \"created_time\": \"2021-02-05T12:04:09.122583Z\", \"created_time_dt\": \"2021-02-05T12:04:09.122583Z\", \"duration\": \"0:01:40\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 96, \"param_--min-data-in-leaf\": 450, \"param_--learning-rate\": 0.1, \"param_--feature-fraction\": 0.7004735549105927, \"param_--bagging-fraction\": 0.4087671886336549, \"param_--bagging-freq\": 15, \"param_--max-rounds\": 1790, \"best_metric\": 26.87029937}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18\", \"run_number\": 20, \"metric\": 26.82074167, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:05:21.956769Z\", \"end_time\": \"2021-02-05T12:06:58.745712Z\", \"created_time\": \"2021-02-05T12:05:12.522962Z\", \"created_time_dt\": \"2021-02-05T12:05:12.522962Z\", \"duration\": \"0:01:46\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 88, \"param_--min-data-in-leaf\": 140, \"param_--learning-rate\": 0.015, \"param_--feature-fraction\": 0.8560920060533119, \"param_--bagging-fraction\": 0.6640337972592919, \"param_--bagging-freq\": 3, \"param_--max-rounds\": 460, \"best_metric\": 26.82074167}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_16\", \"run_number\": 21, \"metric\": 26.88945131, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:05:23.730153Z\", \"end_time\": \"2021-02-05T12:06:25.591698Z\", \"created_time\": \"2021-02-05T12:05:12.979926Z\", \"created_time_dt\": \"2021-02-05T12:05:12.979926Z\", \"duration\": \"0:01:12\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 26, \"param_--min-data-in-leaf\": 150, \"param_--learning-rate\": 0.02, \"param_--feature-fraction\": 0.2, \"param_--bagging-fraction\": 1.0, \"param_--bagging-freq\": 9, \"param_--max-rounds\": 1850, \"best_metric\": 26.82074167}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_17\", \"run_number\": 22, \"metric\": 27.14479669, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:05:24.331475Z\", \"end_time\": \"2021-02-05T12:06:21.147366Z\", \"created_time\": \"2021-02-05T12:05:13.981125Z\", \"created_time_dt\": \"2021-02-05T12:05:13.981125Z\", \"duration\": \"0:01:07\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 39, \"param_--min-data-in-leaf\": 150, \"param_--learning-rate\": 0.1, \"param_--feature-fraction\": 1.0, \"param_--bagging-fraction\": 1.0, \"param_--bagging-freq\": 18, \"param_--max-rounds\": 1860, \"best_metric\": 26.82074167}, {\"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_19\", \"run_number\": 23, \"metric\": 26.91195141, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-05T12:06:57.281841Z\", \"end_time\": \"2021-02-05T12:09:26.117803Z\", \"created_time\": \"2021-02-05T12:06:47.994801Z\", \"created_time_dt\": \"2021-02-05T12:06:47.994801Z\", \"duration\": \"0:02:38\", \"hyperdrive_id\": \"45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"arguments\": null, \"param_--num-leaves\": 37, \"param_--min-data-in-leaf\": 150, \"param_--learning-rate\": 0.03, \"param_--feature-fraction\": 0.35117752823712367, \"param_--bagging-fraction\": 0.41601463279675777, \"param_--bagging-freq\": 5, \"param_--max-rounds\": 1850, \"best_metric\": 26.82074167}], \"children_metrics\": {\"categories\": [0], \"series\": {\"MAE\": [{\"categories\": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], \"mode\": \"markers\", \"name\": \"MAE\", \"stepped\": false, \"type\": \"scatter\", \"data\": [26.904076613759965, 26.91962523809523, 26.907852454557485, 26.910119048886074, 26.904762070516224, 26.94030774633746, 26.904881750139058, 26.966363233986346, 26.904761904761905, 26.870299367086727, 26.930779275887012, 26.94512111813136, 26.874524209236732, 26.904761904761905, 26.904761904761905, 26.904761904761905, 26.820741669022762, 26.889451305548484, 27.144796691600355, 26.911951406961528]}, {\"categories\": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], \"mode\": \"lines\", \"name\": \"MAE_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [26.904076613759965, 26.904076613759965, 26.904076613759965, 26.904076613759965, 26.904076613759965, 26.904076613759965, 26.904076613759965, 26.904076613759965, 26.904076613759965, 26.870299367086727, 26.870299367086727, 26.870299367086727, 26.870299367086727, 26.870299367086727, 26.870299367086727, 26.870299367086727, 26.820741669022762, 26.820741669022762, 26.820741669022762, 26.820741669022762]}]}, \"metricName\": null, \"primaryMetricName\": \"MAE\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": [\"MAE\", \"MAE\", \"MAE\", \"MAE\"], \"timestamp\": [\"2021-02-05 11:58:50.244241+00:00\", \"2021-02-05 12:02:30.498254+00:00\", \"2021-02-05 12:07:11.128491+00:00\", \"2021-02-05 12:07:11.128491+00:00\"], \"run_id\": [\"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_2\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_8\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18\", \"HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18\"], \"metric_value\": [26.904076613759965, 26.870299367086727, 26.820741669022762, 26.820741669022762], \"final\": [false, false, false, true]}]}]}], \"run_logs\": \"[2021-02-05T11:56:46.158127][API][INFO]Experiment created\\r\\n[2021-02-05T11:56:46.676060][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-02-05T11:56:46.9541406Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2021-02-05T11:56:46.972368][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T11:57:17.4447916Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2021-02-05T11:57:17.4465329Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_1'\\r\\n[2021-02-05T11:57:17.4455157Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_0'\\r\\n[2021-02-05T11:57:17.5022450Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_3'\\r\\n[2021-02-05T11:57:17.4679639Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_2'\\r\\n[2021-02-05T11:57:18.0329109Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_2'\\r\\n[2021-02-05T11:57:18.0811738Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_0'\\r\\n[2021-02-05T11:57:18.8218764Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_3'\\r\\n[2021-02-05T11:57:19.0448815Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_1'\\r\\n[2021-02-05T11:58:50.913651][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-02-05T11:58:51.526076][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T11:59:21.5447362Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_4'\\r\\n[2021-02-05T11:59:21.5487349Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_7'\\r\\n[2021-02-05T11:59:21.5477174Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_6'\\r\\n[2021-02-05T11:59:21.5462413Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_5'\\r\\n[2021-02-05T11:59:22.3203172Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_7'\\r\\n[2021-02-05T11:59:22.9488007Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_6'\\r\\n[2021-02-05T11:59:22.9657589Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_5'\\r\\n[2021-02-05T11:59:23.5184334Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_4'\\r\\n[2021-02-05T12:00:28.239794][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2021-02-05T12:00:30.023579][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:00:55.1405136Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_8'\\r\\n[2021-02-05T12:00:55.1419286Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_9'\\r\\n[2021-02-05T12:00:55.8383902Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_9'\\r\\n[2021-02-05T12:00:56.7127796Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_8'\\r\\n[2021-02-05T12:01:00.159662][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-02-05T12:01:01.467538][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:01:28.0952066Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_10'\\r\\n[2021-02-05T12:01:28.7426367Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_10'\\r\\n[2021-02-05T12:01:32.453600][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-02-05T12:01:34.076729][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:01:59.3980440Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_11'\\r\\n[2021-02-05T12:02:00.3642934Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_11'\\r\\n[2021-02-05T12:02:04.160790][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2021-02-05T12:02:05.518152][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:02:31.1789565Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_12'\\r\\n[2021-02-05T12:02:31.1807004Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_13'\\r\\n[2021-02-05T12:02:32.0760520Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_12'\\r\\n[2021-02-05T12:02:32.5300832Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_13'\\r\\n[2021-02-05T12:03:07.421684][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-02-05T12:03:08.402658][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:03:35.9513899Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_14'\\r\\n[2021-02-05T12:03:37.0263239Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_14'\\r\\n[2021-02-05T12:03:39.421837][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-02-05T12:03:40.976233][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:04:08.3372906Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_15'\\r\\n[2021-02-05T12:04:09.3524495Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_15'\\r\\n[2021-02-05T12:04:41.650884][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2021-02-05T12:04:45.039920][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:05:11.8806268Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_16'\\r\\n[2021-02-05T12:05:11.8794886Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_17'\\r\\n[2021-02-05T12:05:11.8783742Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18'\\r\\n[2021-02-05T12:05:12.6172742Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18'\\r\\n[2021-02-05T12:05:13.1797778Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_16'\\r\\n[2021-02-05T12:05:14.0822424Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_17'\\r\\n[2021-02-05T12:06:20.494380][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-02-05T12:06:23.569463][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-05T12:06:47.3550951Z][SCHEDULER][INFO]Scheduling job, id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_19'\\r\\n[2021-02-05T12:06:48.0776041Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_19'\\r\\n[2021-02-05T12:06:56.526076][GENERATOR][INFO]Max number of jobs '20' reached for experiment.\\r\\n[2021-02-05T12:06:56.647838][GENERATOR][INFO]All jobs generated.\\r\\n[2021-02-05T12:09:52.435879][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_45883ed0-be2a-44c6-823d-a646b28c2f1a\n",
      "Web View: https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting/runs/HD_45883ed0-be2a-44c6-823d-a646b28c2f1a?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-137315/workspaces/quick-starts-ws-137315\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2021-02-05T11:56:46.158127][API][INFO]Experiment created<END>\\n\"\"<START>[2021-02-05T11:56:46.676060][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"<START>[2021-02-05T11:56:46.9541406Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\"<START>[2021-02-05T11:56:46.972368][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: HD_45883ed0-be2a-44c6-823d-a646b28c2f1a\n",
      "Web View: https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting/runs/HD_45883ed0-be2a-44c6-823d-a646b28c2f1a?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-137315/workspaces/quick-starts-ws-137315\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_19': {'MAE': 26.911951406961528},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_17': {'MAE': 27.144796691600355},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_16': {'MAE': 26.889451305548484},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18': {'MAE': 26.820741669022762},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_15': {'MAE': 26.904761904761905},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_14': {'MAE': 26.904761904761905},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_13': {'MAE': 26.904761904761905},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_12': {'MAE': 26.874524209236732},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_11': {'MAE': 26.94512111813136},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_10': {'MAE': 26.930779275887012},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_8': {'MAE': 26.870299367086727},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_9': {'MAE': 26.904761904761905},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_5': {'MAE': 26.904881750139058},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_6': {'MAE': 26.94030774633746},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_7': {'MAE': 26.904762070516224},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_4': {'MAE': 26.966363233986346},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_3': {'MAE': 26.907852454557485},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_1': {'MAE': 26.910119048886074},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_2': {'MAE': 26.904076613759965},\n",
       " 'HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_0': {'MAE': 26.91962523809523}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show run details with the Jupyter widget\n",
    "RunDetails(hyperdrive_run).show()\n",
    "hyperdrive_run.wait_for_completion(show_output=True)\n",
    "hyperdrive_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Save Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Id:  HD_45883ed0-be2a-44c6-823d-a646b28c2f1a_18\n",
      "MAE: 26.820741669022762\n",
      "Best model hyperparameter values ['--data-folder', '$AZUREML_DATAREFERENCE_9757c8defdb14ec58bae10673580fcee', '--num-leaves', '88', '--min-data-in-leaf', '140', '--learning-rate', '0.015', '--feature-fraction', '0.8560920060533119', '--bagging-fraction', '0.6640337972592919', '--bagging-freq', '3', '--max-rounds', '460']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best model and its hyperparameter values\n",
    "\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()[\"runDefinition\"][\"arguments\"]\n",
    "\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('MAE:', best_run_metrics['MAE'])\n",
    "print('Best model hyperparameter values', parameter_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "model = best_run.register_model(\n",
    "    model_name=\"hd_lgbm_walmart_forecast\", \n",
    "    model_path=\"./outputs/model\",\n",
    "    description='Best HyperDrive Walmart forecasting model'\n",
    ")\n",
    "print(\"Model successfully saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "**REVIEW AND EDIT**\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service.\n",
    "\n",
    "Now we are ready to deploy the model as a web service running in Azure Container Instance [ACI](https://azure.microsoft.com/en-us/services/container-instances/). Azure Machine Learning accomplishes this by constructing a Docker image with the scoring logic and model baked in.\n",
    "\n",
    "### Create score.py\n",
    "\n",
    "First, we will create a scoring script that will be invoked by the web service call.\n",
    "\n",
    "* Note that the scoring script must have two required functions, `init()` and `run(input_data)`.\n",
    "    - In `init()` function, you typically load the model into a global object. This function is executed only once when the Docker container is started.\n",
    "    - In `run(input_data)` function, the model is used to predict a value based on the input data. The input and output to run typically use JSON as serialization and de-serialization format but you are not limited to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def init():\n",
    "    global bst\n",
    "    model_root = os.getenv(\"AZUREML_MODEL_DIR\")\n",
    "    # The name of the folder in which to look for LightGBM model files\n",
    "    lgbm_model_folder = \"model\"\n",
    "    bst = lgb.Booster(\n",
    "        model_file=os.path.join(model_root, lgbm_model_folder, \"best-model.txt\")\n",
    "    )\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    columns = bst.feature_name()\n",
    "    data = np.array(json.loads(raw_data)[\"data\"])\n",
    "    test_df = pd.DataFrame(data=data, columns=columns)\n",
    "    # Make prediction\n",
    "    out = bst.predict(test_df)\n",
    "    return out.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create myenv.yml\n",
    "\n",
    "We also need to create an environment file so that Azure Machine Learning can install the necessary packages in the Docker image which are required by your scoring script. In this case, we need to specify packages `numpy`, `pandas`, and `lightgbm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.3\n",
      "1.18.5\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults~=1.20.0\n",
      "- numpy=1.18.5\n",
      "- pandas=0.25.3\n",
      "- lightgbm=2.3.0\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package(\"numpy=1.18.5\")\n",
    "cd.add_conda_package(\"pandas=0.25.3\")\n",
    "cd.add_conda_package(\"lightgbm=2.3.0\")\n",
    "cd.save_to_file(base_directory=\"./\", conda_file_path=\"myenv.yml\")\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI\n",
    "\n",
    "We are almost ready to deploy. In the next cell, we first create the inference configuration and deployment configuration. Then, we deploy the model to ACI. This cell will run for several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running...."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "inference_config = InferenceConfig(runtime=\"python\", entry_script=\"score.py\", conda_file=\"myenv.yml\")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                               memory_gb=1,\n",
    "                                               tags={\"name\": \"walmart_tx_data\", \"framework\": \"LightGBM\"},\n",
    "                                               description=\"LightGBM model on Walmart Texas stores data\")\n",
    "\n",
    "aci_service_name = 'hd-walmart-forecast'\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name=aci_service_name, \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deployment state: \" + service.state)\n",
    "print(\"Scoring URI: \" + service.scoring_uri)\n",
    "print(\"Authetication Key: \" + service.get_keys()[0])\n",
    "print(\"Swagger URI: \" + service.swagger_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the deployed model\n",
    "\n",
    "Let's test the deployed model. We create a few test data points and send them to the web service hosted in ACI. Note here we are using the run API in the SDK to invoke the service. You can also make raw HTTP calls using any HTTP tool such as curl.\n",
    "\n",
    "After the invocation, we print the returned predictions each of which represents the forecasted sales of a target store, brand in a given week as specified by `store, brand, week` in `used_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test features (28 days)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 days in the test features dataset\n",
    "X_test['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True, inplace = True)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a few test data points\n",
    "test_samples = json.dumps({\"data\": np.array(X_test.iloc[:3]).tolist()})\n",
    "test_samples = bytes(test_samples, encoding=\"utf8\")\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the deployed model\n",
    "result = service.run(input_data=test_samples)\n",
    "print(\"prediction:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also send raw HTTP request to the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, test_samples, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"\")\n",
    "print(\"input data:\", test_samples)\n",
    "print(\"\")\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "After finishing the tests, you can delete the ACI deployment with a simple delete API call as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX model\n",
    "\n",
    "## Retrieve and save the best ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve and save the best model\n",
    "\n",
    "best_run, onnx_model = hyperdrive_run.get_output(return_onnx_model=True)\n",
    "onnx_model_path = \"results/best_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info < OnnxConvertConstants.OnnxIncompatiblePythonVersion:\n",
    "    python_version_compatible = True\n",
    "else:\n",
    "    python_version_compatible = False\n",
    "\n",
    "def get_onnx_res(run):\n",
    "    res_path = 'onnx_resource.json'\n",
    "    run.download_file(name=constants.MODEL_RESOURCE_PATH_ONNX, output_file_path=res_path)\n",
    "    with open(res_path) as f:\n",
    "        onnx_res = json.load(f)\n",
    "    return onnx_res\n",
    "\n",
    "if python_version_compatible:\n",
    "    test_df = test_data.to_pandas_dataframe()\n",
    "    mdl_bytes = onnx_mdl.SerializeToString()\n",
    "    onnx_res = get_onnx_res(best_run)\n",
    "\n",
    "    onnxrt_helper = OnnxInferenceHelper(mdl_bytes, onnx_res)\n",
    "    pred_onnx, pred_prob_onnx = onnxrt_helper.predict(test_df)\n",
    "\n",
    "    print(pred_onnx)\n",
    "    print(pred_prob_onnx)\n",
    "else:\n",
    "    print('Use Python version 3.6 or 3.7 to run the inference helper.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
