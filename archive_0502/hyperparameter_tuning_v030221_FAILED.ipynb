{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import azureml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "from azureml.core.runconfig import (\n",
    "    RunConfiguration,\n",
    "    EnvironmentDefinition,\n",
    "    CondaDependencies,\n",
    ")\n",
    "\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import BayesianParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, quniform, choice\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "\n",
    "\n",
    "# onnx\n",
    "\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "from azureml.automl.core.onnx_convert import OnnxConvertConstants\n",
    "from azureml.train.automl import constants\n",
    "import onnxruntime\n",
    "from azureml.automl.runtime.onnx_convert import OnnxInferenceHelper\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize workspace and create an Azure ML experiment\n",
    "\n",
    "To start we need to initialize our workspace and create a Azule ML experiment. It is also to remember that accessing the Azure ML workspace requires authentication with Azure.\n",
    "\n",
    "Make sure the config file is present at `.\\config.json`. This file can be downloaded from home of Azure Machine Learning Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-137099\n",
      "aml-quickstarts-137099\n",
      "southcentralus\n",
      "3e42d11f-d64d-4173-af9b-12ecaa1030b3\n"
     ]
    }
   ],
   "source": [
    "#Define the workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>hyper-lgbm-walmart-forecasting</td><td>quick-starts-ws-137099</td><td><a href=\"https://ml.azure.com/experiments/hyper-lgbm-walmart-forecasting?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-137099/workspaces/quick-starts-ws-137099\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: hyper-lgbm-walmart-forecasting,\n",
       "Workspace: quick-starts-ws-137099)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an experiment\n",
    "experiment_name = 'hyper-lgbm-walmart-forecasting'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Workspace name</th>\n",
       "      <td>quick-starts-ws-137099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azure region</th>\n",
       "      <td>southcentralus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription id</th>\n",
       "      <td>3e42d11f-d64d-4173-af9b-12ecaa1030b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource group</th>\n",
       "      <td>aml-quickstarts-137099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>hyper-lgbm-walmart-forecasting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Workspace name                 quick-starts-ws-137099\n",
       "Azure region                           southcentralus\n",
       "Subscription id  3e42d11f-d64d-4173-af9b-12ecaa1030b3\n",
       "Resource group                 aml-quickstarts-137099\n",
       "Experiment Name        hyper-lgbm-walmart-forecasting"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data = {'Workspace name': ws.name,\n",
    "            'Azure region': ws.location,\n",
    "            'Subscription id': ws.subscription_id,\n",
    "            'Resource group': ws.resource_group,\n",
    "            'Experiment Name': experiment.name}\n",
    "\n",
    "df_data = pd.DataFrame.from_dict(data = dic_data, orient='index')\n",
    "\n",
    "df_data.rename(columns={0:''}, inplace = True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpu-cluster. Use it.\n",
      "\n",
      "Running\n",
      "{'errors': [], 'creationTime': '2021-02-03T15:05:32.794995+00:00', 'createdBy': {'userObjectId': '3a8b1748-42f5-4ca5-890b-924cd9b78bd9', 'userTenantId': '660b3398-b80e-49d2-bc5b-ac1dc93b5254', 'userName': None}, 'modifiedTime': '2021-02-03T15:08:19.029743+00:00', 'state': 'Running', 'vmSize': 'STANDARD_DS12_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Define CPU cluster name\n",
    "compute_target_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "    print(\"Found existing cpu-cluster. Use it.\")\n",
    "except ComputeTargetException:\n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_DS12_V2\",\n",
    "                                                           min_nodes=1, # when innactive\n",
    "                                                           max_nodes=4) # when busy\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    compute_target = ComputeTarget.create(ws, compute_target_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status()\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Docker environment\n",
    "\n",
    "The remote compute will need to create a [Docker image](https://docs.docker.com/get-started/) for running the script. The Docker image is an encapsulated environment with necessary dependencies installed. In the following cell, we specify the conda packages and Python version that are needed for running the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = EnvironmentDefinition()\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=[\"pandas\", \"numpy\", \"scipy\", \"scikit-learn\", \"lightgbm\", \"joblib\"],\n",
    "    python_version=\"3.6.2\",\n",
    ")\n",
    "env.python.conda_dependencies.add_channel(\"conda-forge\")\n",
    "env.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The dataset used in this project is a small subset of a much bigger dataset made available at Kaggle's competition [M5 Forecasting - Accuracy Estimate the unit sales of Walmart retail goods](https://www.kaggle.com/c/m5-forecasting-accuracy/overview/description).\n",
    "\n",
    "The complete dataset covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. **The task is to forecast daily sales for the next 28 days.**\n",
    "\n",
    "In order to demonstrate the use of Azure ML in forecasting we used the available data consisting of the following files and create a reduced dataset with **10 products of the 3 Texas stores of Walmart**. \n",
    "\n",
    "* **calendar.csv** - Contains information about the dates on which the products are sold.\n",
    "* **sell_prices.csv** - Contains information about the price of the products sold per store and date.\n",
    "* **sales_train_evaluation.csv** - Includes sales [d_1 - d_1941] (labels used for the Public leaderboard)\n",
    "\n",
    "Details on how the new dataset was created can be seen in notebook [01-walmart_data_preparation](http://localhost:8888/notebooks/Capstone%20Project/notebooks/01-walmart_data_preparation.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_2_001_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_001</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_2_002_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_002</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_2_003_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_003</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_2_004_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_004</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_2_005_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_005</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_2_001_TX_1_evaluation  HOBBIES_2_001  HOBBIES_2  HOBBIES     TX_1   \n",
       "1  HOBBIES_2_002_TX_1_evaluation  HOBBIES_2_002  HOBBIES_2  HOBBIES     TX_1   \n",
       "2  HOBBIES_2_003_TX_1_evaluation  HOBBIES_2_003  HOBBIES_2  HOBBIES     TX_1   \n",
       "3  HOBBIES_2_004_TX_1_evaluation  HOBBIES_2_004  HOBBIES_2  HOBBIES     TX_1   \n",
       "4  HOBBIES_2_005_TX_1_evaluation  HOBBIES_2_005  HOBBIES_2  HOBBIES     TX_1   \n",
       "\n",
       "  state_id  day  demand       date  wm_yr_wk event_name_1 event_type_1  \\\n",
       "0       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "1       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "2       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "3       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "4       TX  d_1       0 2011-01-29     11101          NaN          NaN   \n",
       "\n",
       "  event_name_2 event_type_2  snap_TX  sell_price  \n",
       "0          NaN          NaN        0         nan  \n",
       "1          NaN          NaN        0        1.97  \n",
       "2          NaN          NaN        0         nan  \n",
       "3          NaN          NaN        0         nan  \n",
       "4          NaN          NaN        0         nan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_column_name = 'date'\n",
    "data = pd.read_csv(\"./data/walmart_tx_stores_10_items_with_day.csv\",parse_dates=[time_column_name])\n",
    "# data = pd.read_csv(\"https://raw.githubusercontent.com/dpbac/Forecasting-Walmart-sales-with-Azure/master/data/walmart_tx_stores_10_items_with_day.csv?token=AEBB67N7Y3QIIH36FY5PBEDADK6WQ\", parse_dates=[time_column_name])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58230 entries, 0 to 58229\n",
      "Data columns (total 16 columns):\n",
      "id              58230 non-null object\n",
      "item_id         58230 non-null object\n",
      "dept_id         58230 non-null object\n",
      "cat_id          58230 non-null object\n",
      "store_id        58230 non-null object\n",
      "state_id        58230 non-null object\n",
      "day             58230 non-null object\n",
      "demand          58230 non-null int64\n",
      "date            58230 non-null datetime64[ns]\n",
      "wm_yr_wk        58230 non-null int64\n",
      "event_name_1    4740 non-null object\n",
      "event_type_1    4740 non-null object\n",
      "event_name_2    120 non-null object\n",
      "event_type_2    120 non-null object\n",
      "snap_TX         58230 non-null int64\n",
      "sell_price      52938 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(11)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 28\n",
    "gap = 0\n",
    "\n",
    "data = create_features(data,forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41988 entries, 10951 to 58229\n",
      "Data columns (total 42 columns):\n",
      "id                          41988 non-null category\n",
      "item_id                     41988 non-null category\n",
      "dept_id                     41988 non-null category\n",
      "cat_id                      41988 non-null category\n",
      "store_id                    41988 non-null category\n",
      "state_id                    41988 non-null category\n",
      "day                         41988 non-null category\n",
      "demand                      41988 non-null int64\n",
      "date                        41988 non-null datetime64[ns]\n",
      "wm_yr_wk                    41988 non-null int64\n",
      "event_name_1                41988 non-null category\n",
      "event_type_1                41988 non-null category\n",
      "event_name_2                41988 non-null category\n",
      "event_type_2                41988 non-null category\n",
      "snap_TX                     41988 non-null int64\n",
      "sell_price                  41988 non-null float64\n",
      "lag_t28                     41988 non-null float64\n",
      "lag_t29                     41988 non-null float64\n",
      "lag_t30                     41988 non-null float64\n",
      "rolling_mean_t7             41988 non-null float64\n",
      "rolling_std_t7              41988 non-null float64\n",
      "rolling_mean_t30            41988 non-null float64\n",
      "rolling_std_t30             41988 non-null float64\n",
      "rolling_mean_t90            41988 non-null float64\n",
      "rolling_std_t90             41988 non-null float64\n",
      "rolling_mean_t180           41988 non-null float64\n",
      "rolling_std_t180            41988 non-null float64\n",
      "price_change_t1             41988 non-null float64\n",
      "price_change_t365           41988 non-null float64\n",
      "rolling_price_std_t7        41988 non-null float64\n",
      "rolling_price_std_t30       41988 non-null float64\n",
      "day_of_month                41988 non-null int64\n",
      "day_of_week                 41988 non-null int64\n",
      "week                        41988 non-null int64\n",
      "month                       41988 non-null int64\n",
      "year                        41988 non-null int64\n",
      "is_month_start              41988 non-null int64\n",
      "is_month_end                41988 non-null int64\n",
      "is_weekend                  41988 non-null int64\n",
      "lag_revenue_t1              41988 non-null float64\n",
      "rolling_revenue_std_t28     41988 non-null float64\n",
      "rolling_revenue_mean_t28    41988 non-null float64\n",
      "dtypes: category(11), datetime64[ns](1), float64(19), int64(11)\n",
      "memory usage: 10.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First day training dataset:2012-01-29 00:00:00\n",
      "Last day training dataset:2016-04-24 00:00:00\n",
      "First day test dataset:2016-04-25 00:00:00\n",
      "Last day test dataset:2016-05-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create a training/testing split\n",
    "\n",
    "df_train, df_test = split_train_test(data,forecast_horizon, gap)\n",
    "\n",
    "# Separate features and labels\n",
    "    \n",
    "X_train=df_train.drop(['demand'],axis=1)\n",
    "y_train=df_train['demand']\n",
    "X_test=df_test.drop(['demand'],axis=1)\n",
    "y_test=df_test['demand']\n",
    "    \n",
    "X_train.drop(columns='date',inplace=True)\n",
    "X_test.drop(columns='date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading ./test.csv\n",
      "Uploaded ./test.csv, 1 files out of an estimated total of 3\n",
      "Uploading ./data_walmart_tx.csv\n",
      "Uploaded ./data_walmart_tx.csv, 2 files out of an estimated total of 3\n",
      "Uploading ./train.csv\n",
      "Uploaded ./train.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_12f3d719c5ee402480d5fe864a04ce80"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save data locally\n",
    "    \n",
    "path_data = './data_walmart_tx.csv'\n",
    "path_train = './train.csv'\n",
    "path_test = './test.csv'\n",
    "\n",
    "data.to_csv(path_data, index = None, header=True)\n",
    "df_train.to_csv(path_train, index = None, header=True)\n",
    "df_test.to_csv(path_test, index = None, header=True)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload_files(files = ['./data_walmart_tx.csv','./train.csv', './test.csv'], \n",
    "                       target_path = 'dataset/', \n",
    "                       overwrite = True,\n",
    "                       show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data locally\n",
    "\n",
    "# path_data = './data_walmart_tx.csv'\n",
    "# path_train = './train.csv'\n",
    "# path_test = './test.csv'\n",
    "\n",
    "# data.to_csv(path_data, index = None, header=True)\n",
    "# df_train.to_csv(path_train, index = None, header=True)\n",
    "# df_test.to_csv(path_test, index = None, header=True)\n",
    "\n",
    "# datastore = ws.get_default_datastore()\n",
    "\n",
    "# path_on_datastore = \"dataset/\"\n",
    "# datastore.upload_files(files = ['./walmart_data_tx.csv','./train.csv', './test.csv'], \n",
    "#                        target_path = 'dataset/', \n",
    "#                        overwrite = True,\n",
    "#                        show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore type: AzureBlob\n",
      "Account name: mlstrg137099\n",
      "Container name: azureml-blobstore-c1597f18-627d-4679-940e-b9fce33fcffc\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Datastore type: \" + datastore.datastore_type,\n",
    "    \"Account name: \" + datastore.account_name,\n",
    "    \"Container name: \" + datastore.container_name,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_7e0abfff6611428b8067cabf14d00de3\n"
     ]
    }
   ],
   "source": [
    "# Get data reference object for the data path\n",
    "ds_data = datastore.path('dataset/')\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.data.data_reference.DataReference"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds_data.as_mount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "df_temp = Dataset.Tabular.from_delimited_files(path=datastore.path('dataset/train.csv'))\n",
    "df_temp = df_temp.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.data.data_reference.DataReference"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datastore.path('dataset/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_revenue_t1</th>\n",
       "      <th>rolling_revenue_std_t28</th>\n",
       "      <th>rolling_revenue_mean_t28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_2_002_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_002</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_2_007_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_007</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_2_009_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_009</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.39</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_2_001_TX_2_evaluation</td>\n",
       "      <td>HOBBIES_2_001</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_2_002_TX_2_evaluation</td>\n",
       "      <td>HOBBIES_2_002</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>TX</td>\n",
       "      <td>d_366</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_2_002_TX_1_evaluation  HOBBIES_2_002  HOBBIES_2  HOBBIES     TX_1   \n",
       "1  HOBBIES_2_007_TX_1_evaluation  HOBBIES_2_007  HOBBIES_2  HOBBIES     TX_1   \n",
       "2  HOBBIES_2_009_TX_1_evaluation  HOBBIES_2_009  HOBBIES_2  HOBBIES     TX_1   \n",
       "3  HOBBIES_2_001_TX_2_evaluation  HOBBIES_2_001  HOBBIES_2  HOBBIES     TX_2   \n",
       "4  HOBBIES_2_002_TX_2_evaluation  HOBBIES_2_002  HOBBIES_2  HOBBIES     TX_2   \n",
       "\n",
       "  state_id    day  demand       date  wm_yr_wk  ... day_of_week week month  \\\n",
       "0       TX  d_366       2 2012-01-29     11201  ...           6    4     1   \n",
       "1       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "2       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "3       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "4       TX  d_366       0 2012-01-29     11201  ...           6    4     1   \n",
       "\n",
       "   year  is_month_start  is_month_end  is_weekend  lag_revenue_t1  \\\n",
       "0  2012               0             0           1            0.00   \n",
       "1  2012               0             0           1            0.00   \n",
       "2  2012               0             0           1            0.00   \n",
       "3  2012               0             0           1            0.00   \n",
       "4  2012               0             0           1            0.00   \n",
       "\n",
       "   rolling_revenue_std_t28  rolling_revenue_mean_t28  \n",
       "0                     1.86                      0.63  \n",
       "1                     0.31                      0.10  \n",
       "2                     7.39                      3.39  \n",
       "3                     1.72                      0.59  \n",
       "4                     2.76                      2.04  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41148 entries, 0 to 41147\n",
      "Data columns (total 42 columns):\n",
      "id                          41148 non-null object\n",
      "item_id                     41148 non-null object\n",
      "dept_id                     41148 non-null object\n",
      "cat_id                      41148 non-null object\n",
      "store_id                    41148 non-null object\n",
      "state_id                    41148 non-null object\n",
      "day                         41148 non-null object\n",
      "demand                      41148 non-null int64\n",
      "date                        41148 non-null datetime64[ns]\n",
      "wm_yr_wk                    41148 non-null int64\n",
      "event_name_1                41148 non-null object\n",
      "event_type_1                41148 non-null object\n",
      "event_name_2                41148 non-null object\n",
      "event_type_2                41148 non-null object\n",
      "snap_TX                     41148 non-null int64\n",
      "sell_price                  41148 non-null float64\n",
      "lag_t28                     41148 non-null float64\n",
      "lag_t29                     41148 non-null float64\n",
      "lag_t30                     41148 non-null float64\n",
      "rolling_mean_t7             41148 non-null float64\n",
      "rolling_std_t7              41148 non-null float64\n",
      "rolling_mean_t30            41148 non-null float64\n",
      "rolling_std_t30             41148 non-null float64\n",
      "rolling_mean_t90            41148 non-null float64\n",
      "rolling_std_t90             41148 non-null float64\n",
      "rolling_mean_t180           41148 non-null float64\n",
      "rolling_std_t180            41148 non-null float64\n",
      "price_change_t1             41148 non-null float64\n",
      "price_change_t365           41148 non-null float64\n",
      "rolling_price_std_t7        41148 non-null float64\n",
      "rolling_price_std_t30       41148 non-null float64\n",
      "day_of_month                41148 non-null int64\n",
      "day_of_week                 41148 non-null int64\n",
      "week                        41148 non-null int64\n",
      "month                       41148 non-null int64\n",
      "year                        41148 non-null int64\n",
      "is_month_start              41148 non-null int64\n",
      "is_month_end                41148 non-null int64\n",
      "is_weekend                  41148 non-null int64\n",
      "lag_revenue_t1              41148 non-null float64\n",
      "rolling_revenue_std_t28     41148 non-null float64\n",
      "rolling_revenue_mean_t28    41148 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(19), int64(11), object(11)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperdrive Configuration\n",
    "\n",
    "Before configuring HyperDrive, we will check if the remote compute target is successfully created by submitting a job to the target. This compute target will be used by HyperDrive for hyperparameter tuning later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_7e0abfff6611428b8067cabf14d00de3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_data.as_mount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": true,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": \"2g\"\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": null,\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.20.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"pandas\",\n",
       "                \"numpy\",\n",
       "                \"scipy\",\n",
       "                \"scikit-learn\",\n",
       "                \"lightgbm\",\n",
       "                \"joblib\"\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": null\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.train.estimator._estimator:'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n",
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6c883901aea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Submit job to remote compute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrun_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_jupyter_common/__init__.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_experiment_submit_notebook_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0m_update_run_created_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/_estimator_helper.py\u001b[0m in \u001b[0;36m_estimator_submit_method\u001b[0;34m(estimator, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             source_directory_data_store=source_directory_data_store)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mexperiment_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moverride_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/estimator/_mml_base_estimator.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, workspace, experiment_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_submitted_runconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelemetry_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_override_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_directory_data_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/estimator/_mml_base_estimator.py\u001b[0m in \u001b[0;36m_submit\u001b[0;34m(self, workspace, experiment_name, telemetry_values)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_create_in_cloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_script_run_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelemetry_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mexperiment_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m                 \u001b[0mactivity_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Experiment was submitted. RunId=%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_jupyter_common/__init__.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_experiment_submit_notebook_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0m_update_run_created_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/script_run_config.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(script_run_config, workspace, experiment_name, run_id, _parent_run_id)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_create_in_cloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscript_run_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mrun_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_run_config_from_script_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_run_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_project/project.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, experiment, auth, _disable_service_check)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_snapshots_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSnapshotsClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mabspath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;34m\"\"\"Return an absolute path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not tuple"
     ]
    }
   ],
   "source": [
    "script_params = {\"--bagging-fraction\": 0.8}\n",
    "# script_params = {\"--data-folder\": ds_data.as_mount(), \"--bagging-fraction\": 0.8}\n",
    "script_folder = './', # directory containing experiment configuration files (train.py)\n",
    "train_script_name = 'train.py'\n",
    "\n",
    "# create an estimator to specify details of the job\n",
    "est = Estimator(\n",
    "    source_directory=script_folder,\n",
    "    script_params=script_params,\n",
    "    compute_target=compute_target,\n",
    "    use_docker=True,\n",
    "    entry_script=train_script_name,\n",
    "    environment_definition=env,\n",
    ")\n",
    "\n",
    "# Submit job to remote compute\n",
    "run_remote = experiment.submit(config=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'est' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d83f660a08bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'est' is not defined"
     ]
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the status of the job.\n",
    "RunDetails(run_remote).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation metric value after the job finishes\n",
    "run_remote.wait_for_completion()\n",
    "run_remote.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings.\n",
    "\n",
    "**REVIEW AND EDIT**\n",
    "\n",
    "Now we are ready to tune hyperparameters of the LightGBM forecast model by launching multiple runs on the cluster. In the following cell, we define the configuration of a HyperDrive job that does a parallel search of the hyperparameter space using a Bayesian sampling method. HyperDrive also supports random sampling of the parameter space.\n",
    "\n",
    "It is recommended that the maximum number of runs should be greater than or equal to 20 times the number of hyperparameters being tuned, for best results with Bayesian sampling. Specifically, it should be no less than 180 in the following case as we have 9 hyperparameters to tune. Nevertheless, we find that even with a very small amount of runs Bayesian search can achieve decent performance. Thus, the maximum number of child runs of HyperDrive `max_total_runs` is set as `20` to reduce the running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters using HyperDrive\n",
    "\n",
    "The following code tune hyperparameters for the LightGBM forecast model.\n",
    "\n",
    "The code does a parallel search of the hyperparameter space using a `Bayesian sampling method` which does not support `termination policy`. Therefore, `policy=None`.\n",
    "\n",
    "For Bayesian Sampling we recommend using a `maximum number of runs` greater than or equal to 20 times the number of hyperparameters being tuned. The recommendend value is 140. We set the maximum number of child runs of HyperDrive `max_total_runs` to `20` to reduce the running time. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**If I have the time:**\n",
    "Therefore, we set the maximum number of child runs of HyperDrive `max_total_runs` to `140`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase this value if you want to achieve better performance\n",
    "max_total_runs = 20\n",
    "script_folder = './', # directory containing experiment configuration files (train.py)\n",
    "# script_params = {\"--data-folder\": './'}\n",
    "train_script_name = 'train.py'\n",
    "\n",
    "# Create an estimator for use with train.py\n",
    "est = Estimator(\n",
    "    source_directory=script_folder,\n",
    "#     script_params=script_params,\n",
    "    compute_target=compute_target,\n",
    "    use_docker=True,\n",
    "    entry_script=train_script_name,\n",
    "    environment_definition=env,\n",
    ")\n",
    "\n",
    "# Specify hyperparameter space\n",
    "param_sampling = BayesianParameterSampling(\n",
    "    {\n",
    "        \"--num-leaves\": quniform(8, 128, 1),\n",
    "        \"--min-data-in-leaf\": quniform(20, 500, 10),\n",
    "        \"--learning-rate\": choice(\n",
    "            1e-4, 1e-3, 5e-3, 1e-2, 1.5e-2, 2e-2, 3e-2, 5e-2, 1e-1\n",
    "        ),\n",
    "        \"--feature-fraction\": uniform(0.2, 1),\n",
    "        \"--bagging-fraction\": uniform(0.1, 1),\n",
    "        \"--bagging-freq\": quniform(1, 20, 1),\n",
    "        \"--max-rounds\": quniform(50, 2000, 10),\n",
    "#         \"--max-lag\": quniform(3, 40, 1),\n",
    "#         \"--window-size\": quniform(3, 40, 1),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    estimator=est,\n",
    "    hyperparameter_sampling=param_sampling,\n",
    "    primary_metric_name='MAE',# mean_absolute_error\n",
    "    primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "    max_total_runs=max_total_runs, \n",
    "    max_concurrent_runs=4,\n",
    "    policy=None, #Bayesian sampling does not support early termination policies.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit hyperdrive run to the experiment \n",
    "\n",
    "hyperdrive_run = experiment.submit(config = hyperdrive_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show run details with the Jupyter widget\n",
    "RunDetails(hyperdrive_run).show()\n",
    "hyperdrive_run.wait_for_completion(show_output=True)\n",
    "hyperdrive_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Save Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model and its hyperparameter values\n",
    "\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()[\"runDefinition\"][\"arguments\"]\n",
    "\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('MAE:', best_run_metrics['mean_absolute_error'])\n",
    "print('Best model hyperparameter values', parameter_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model = best_run.register_model(\n",
    "    model_name=\"hd_lgbm_walmart_forecast\", \n",
    "    model_path=\"./outputs/model.pkl\",\n",
    "    description='Best HyperDrive Walmart forecasting model'\n",
    ")\n",
    "print(\"Model successfully saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "**REVIEW AND EDIT**\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service.\n",
    "\n",
    "Now we are ready to deploy the model as a web service running in Azure Container Instance [ACI](https://azure.microsoft.com/en-us/services/container-instances/). Azure Machine Learning accomplishes this by constructing a Docker image with the scoring logic and model baked in.\n",
    "\n",
    "### Create score.py\n",
    "\n",
    "First, we will create a scoring script that will be invoked by the web service call.\n",
    "\n",
    "* Note that the scoring script must have two required functions, `init()` and `run(input_data)`.\n",
    "    - In `init()` function, you typically load the model into a global object. This function is executed only once when the Docker container is started.\n",
    "    - In `run(input_data)` function, the model is used to predict a value based on the input data. The input and output to run typically use JSON as serialization and de-serialization format but you are not limited to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def init():\n",
    "    global bst\n",
    "    model_root = os.getenv(\"AZUREML_MODEL_DIR\")\n",
    "    # The name of the folder in which to look for LightGBM model files\n",
    "    lgbm_model_folder = \"model\"\n",
    "    bst = lgb.Booster(\n",
    "        model_file=os.path.join(model_root, lgbm_model_folder, \"best-model.txt\")\n",
    "    )\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    columns = bst.feature_name()\n",
    "    data = np.array(json.loads(raw_data)[\"data\"])\n",
    "    test_df = pd.DataFrame(data=data, columns=columns)\n",
    "    # Make prediction\n",
    "    out = bst.predict(test_df)\n",
    "    return out.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create myenv.yml\n",
    "\n",
    "We also need to create an environment file so that Azure Machine Learning can install the necessary packages in the Docker image which are required by your scoring script. In this case, we need to specify packages `numpy`, `pandas`, and `lightgbm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package(\"numpy=1.16.2\")\n",
    "cd.add_conda_package(\"pandas=0.23.4\")\n",
    "cd.add_conda_package(\"lightgbm=2.3.0\")\n",
    "cd.save_to_file(base_directory=\"./\", conda_file_path=\"myenv.yml\")\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI\n",
    "\n",
    "We are almost ready to deploy. In the next cell, we first create the inference configuration and deployment configuration. Then, we deploy the model to ACI. This cell will run for several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inference_config = InferenceConfig(runtime=\"python\", entry_script=\"score.py\", conda_file=\"myenv.yml\")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                               memory_gb=1,\n",
    "                                               tags={\"name\": \"walmart_tx_data\", \"framework\": \"LightGBM\"},\n",
    "                                               description=\"LightGBM model on Walmart Texas stores data\")\n",
    "\n",
    "aci_service_name = 'hd-walmart-forecast'\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name=aci_service_name, \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deployment state: \" + service.state)\n",
    "print(\"Scoring URI: \" + service.scoring_uri)\n",
    "print(\"Authetication Key: \" + service.get_keys()[0])\n",
    "print(\"Swagger URI: \" + service.swagger_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the deployed model\n",
    "\n",
    "Let's test the deployed model. We create a few test data points and send them to the web service hosted in ACI. Note here we are using the run API in the SDK to invoke the service. You can also make raw HTTP calls using any HTTP tool such as curl.\n",
    "\n",
    "After the invocation, we print the returned predictions each of which represents the forecasted sales of a target store, brand in a given week as specified by `store, brand, week` in `used_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test features (28 days)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 days in the test features dataset\n",
    "X_test['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True, inplace = True)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a few test data points\n",
    "test_samples = json.dumps({\"data\": np.array(X_test.iloc[:3]).tolist()})\n",
    "test_samples = bytes(test_samples, encoding=\"utf8\")\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the deployed model\n",
    "result = service.run(input_data=test_samples)\n",
    "print(\"prediction:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also send raw HTTP request to the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, test_samples, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"\")\n",
    "print(\"input data:\", test_samples)\n",
    "print(\"\")\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "After finishing the tests, you can delete the ACI deployment with a simple delete API call as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX model\n",
    "\n",
    "## Retrieve and save the best ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve and save the best model\n",
    "\n",
    "best_run, onnx_model = hyperdrive_run.get_output(return_onnx_model=True)\n",
    "onnx_model_path = \"results/best_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info < OnnxConvertConstants.OnnxIncompatiblePythonVersion:\n",
    "    python_version_compatible = True\n",
    "else:\n",
    "    python_version_compatible = False\n",
    "\n",
    "def get_onnx_res(run):\n",
    "    res_path = 'onnx_resource.json'\n",
    "    run.download_file(name=constants.MODEL_RESOURCE_PATH_ONNX, output_file_path=res_path)\n",
    "    with open(res_path) as f:\n",
    "        onnx_res = json.load(f)\n",
    "    return onnx_res\n",
    "\n",
    "if python_version_compatible:\n",
    "    test_df = test_data.to_pandas_dataframe()\n",
    "    mdl_bytes = onnx_mdl.SerializeToString()\n",
    "    onnx_res = get_onnx_res(best_run)\n",
    "\n",
    "    onnxrt_helper = OnnxInferenceHelper(mdl_bytes, onnx_res)\n",
    "    pred_onnx, pred_prob_onnx = onnxrt_helper.predict(test_df)\n",
    "\n",
    "    print(pred_onnx)\n",
    "    print(pred_prob_onnx)\n",
    "else:\n",
    "    print('Use Python version 3.6 or 3.7 to run the inference helper.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
